[ { "title": "Transformer(NIPS 2017)", "url": "/posts/Transformer-review/", "categories": "Paper Review", "tags": "deeplearning", "date": "2022-12-27 14:00:12 +0900", "snippet": "TransformerDevelopment of Machine Translation based on Deep Learning Since 2021, new models are based on Transformer architecture GPT: Based on Transformer’s Decoder BERT: Based on Transformer’s Encoder The limit of Seq2Seq models Information of source sentences are compressed into context vector $v$ This results in bottleneck and decreases the performance of the model Problem : Having a fixed contextz vector that includes all the information about the source sentences reduced the model performanceSolution : Inputting each output of the source sentences could solve the problem because the GPU has a large memory and has a capability to calculate parellelySeq2Seq with Attention Uses an attention mechanism with Seq2Seq model each hidden state is saved and later used in decoder DecoderAttention As said in the title ‘Attention Is All You Need’ transformer doesn’t need RNN or CNN instead it uses Positional Encoding (Where the word is placed) 3 inputs required Query Key Value Multi-Head AttentionEmbedding Before input goes into the model, each word is embedded To not use the RNN model, Position Encoding needs to used Then it is inputted into Multi-head Attention For performance, Residual Learning is used" }, { "title": "DALL-E Paper Review", "url": "/posts/DALL-E-(OpenAI-2021)-review/", "categories": "Paper Review", "tags": "computer_vision", "date": "2022-12-20 21:19:04 +0900", "snippet": "What is DALL-EDALL-E is a GPT-3 based model that has has 12 billion parameters and is trained with 250 million data Personifying object is possible, combining two different concept which are unrelated is possible It shows great performance without complex architecture or additional label info Well trained DALL-E shows a great performance even in zero-shot situationsBackground InfoTransformer: Attention is All You Need (NIPS 2017) In traditional transformer the output of the last encoder layer is inputted into all the decoder layerGPT-2: Language Models are Unsupervised Multitask Learners(OpenAI 2019) GPT-2 architecture is based on transformer’s decoder It is a large languange model trained with large data set The GPT-2 autoregressively models the text token as a single stream of data A sequence of tokens are inputted and the output is added to the back of the sequence which will later be inputted againHow text is created with a Language Model A language model can generate new text by iteratively sampling $\\displaystyle \\boldsymbol{\\hat{x}_{i+1}}$ $\\displaystyle \\boldsymbol{\\hat{x}{i+1}, f\\theta(x_{i+1} x_1,x_2,\\ldots,x_i)}$ and then feeding sampling $\\displaystyle \\boldsymbol{\\hat{x}_{i+1}}$back into the model to sample $\\displaystyle \\boldsymbol{\\hat{x}_{i+2}}$Equation: $\\displaystyle \\boldsymbol{\\hat{x}{i+2}, f\\theta(x_{i+2}|x_1,x_2,\\ldots, x_{i+1})}$ This process is repeated until the desired stopping criterion is reached Variation of the smapling methods: “greedy” sampling, top-n sampling, … Auto-Encoder This neural network can effectively train data encoding During training, input data and output data are set as same All of the input image is turned into latent vector and return back to its normal state The advantages of it is that input images can turn into conpressed latent code Variational Auto-Encoder(VAE) VAE’s decoder assume the latent code to be in a Gaussian distribution The AE made as distint as possible from each other, this leads to gaps between data points On the right plots, the VAE represents the two core mean values on the graph x-y axes Each mean-pair can generate many representations The goal of VAE is to maximize the lower bound which is $\\displaystyle \\boldsymbol{\\log{p(x)}}$ also known as ELBO(Evidence of Lower Bound)Motivation Recent large-scale generative models based on auto-regressive transformer is doing an outstanding job Generative Pre-training from Pixels (NIPS 2020) GPT-2: Language Models are Unsupervised Multitask Learners (OpenAI 2019) Jukebox: A Generative Model for Music (OpenAI 2020) However Text-to-image translation is not researched enought compared to the model shown above currently text-to-image translation studies are using small datasets such as MS-COCO or CUB-200 In this research large datasets were used for increase in performanceDALL-E Training Process It has a two-satge training procedure like VQ-VAE-2 256 x 256 image is compressed into 32 x 32 imgae token grid (Each token is assigned from one of 8192 tokens) by doing this it can reduce the context size of the transformer to 8 x 8 x 3 withought quality lose It is more effective than creating consecutive pixels 256 BPE-encoded text tokens and 1024 image tokens can be inputted consecutively Autoregressive transformer is trained to model joint distribution of text tokens and image tokens First maximum of 256 text token in inputted, then maxiimum of 1024 image tokens are inputtedSTAGE ONE: Learning the Visual Codebook First dVAE encoder and DVAE decoder is trained with transformer being fixed At this moment prior transformer is set to uniform categorical distribution DALL-E solves the discrete problem using gumbel softmax relaxation Simply choosing one index from the codebook vector using argmax prevents calculating the gradient softmax has to be used instead of argmax In the end sampled latent vector z is used for training instead of argaxSTAGE TWO: Learning the Prior Then dVAE encoder and dVAE decoder is fixed and the prior distribution (transformer) is trained Image token goes through argmax sampling from dVAE encoder’s results which are logits. Vairous types of attention mask is used for giving attention to all text tokenss Image Analyze Result After training, number of N images are made according to a text In this paper the N value was 512" }, { "title": "Progressive GAN Paper Review", "url": "/posts/ProgressiveGAN-review/", "categories": "Paper Review", "tags": "computer_vision", "date": "2022-11-07 21:19:04 +0900", "snippet": "Progressive Growing of GANs For Improved Quality, Stability and Variation1. Abstract1. ProblemPGGAN(Progressive Growing of GANs) became a big issue when it was first introduced in 2017 Nvidia’s paper.On a typical GAN model, creating a high resolution image can cause some problems. Creating a high resolution image is very hard. Because as the image resolution gets higher, discriminator has a hard time distinguishing the fake image created by thre generator Eventhough if it can create a high resolution, because of the memory limit, the batch size has to become smaller. Smaller batch sizes result in unstable traingin process.2. ApproachThe keypoint proposed in this paper is to gradually develop Generators and Discriminators. The layer is gradually added to from low resolution to high resolution. Through this gradual process of adding layers and training, high resolution images are gradually created (this paper shows 1024 x 1024 images were generated in this way).2. Progressive Growing of GANs1. What are the advantages of gradually adding layers to train?Image Distribution helps us first discover the Large Scale structure. In other words, the keypoint of the paper is “to train by gradually stacking the models of Generators and Discriminators.” At first, we trained the overall contents of a person’s face by looking at the large scale, which is a feature that can only be seen in low-resolutions, and as we gradually build up the layer, we train to look at detailed features such as eyes noes mouth and more.In this paper it says that when adding a layer to the model, the new layer is added smooth and fades in. This means that it prevents having a sudden shock for other layers of the previous steps that have already been well trained.The method of training by gradually stacking layers has the advantage of being stable during training.In addition, the method of gradually stacking layers and generating a high resolution image has the advantage of training with latent vector being mapped according to othe resolution. Therefore, it can create a high resolution image stably.2. Training MethodsUpScalingFor easy understanding I’ll give you an example. When you watch TV, if you watch a normal video on a UHD screen, the screen will look blurry because it cannot fill all horizontal and vertical pixels. It can be solved with upscaling. Upscaling fills in missing pixels and makes the image more clear.Fade InDuring transition(Up Scaling in G, Down Scaling in D), weight is controlled by alpha to stabilize its increase from 0 to 1. Therefore, the weight increases linearly from 0 to 1 while the layer is completely trained.Normalization in Generator and DiscriminatorIn general GAN model has a escalation of signal magnitudes due to unnecessary competition between Generator and Discriminator. To suppress this, the Batch Normalization method was used, which was introduced to eliminate the convolutional shift phenomenon. However, they didn’t use Batch Norm in this paper because they didn’t see any problem with the Covariate shift. Then you might wonder what normalization they used here, but they solved the escalation of signal magnities problem using Pixelwise feature vector normalization, which is summarized right below.Pixelwise Feature Vector NormalizationOne of the normalization methods used in deep learning is Batch Normalization. However, it is said in this paper that batch normalization is not effective. Instead Pixelwise normalization was used. Pixelwise normalization is where the Feature Vector for each pixel is normalized for each unit of lenght and applied to the last end of each layer.So why use Pixelwise Normalization instead of Batch Normalization?It is said to be a technique used by Generator and Discriminator to prevent Magnitude from getting out of control as a result of competition./In more detail, each convolution layer is normalized with Pixelwise for the Feature layer, and local response normalization is modified and implemented.Althogh the method does not significantly change the outcome, it is known to effectively prevent escalation of signal magnitudes during training.Down ScalingIt can be seen as a procedure for inferring information of a high resolutipon from a low resolution.Here are the steps of the training process.[Step 1]Downscale the real images according to the current resolution of the network. Then the image becomes a low resolution image but it still has all the information[Step 2]In the process of Resolution Transition, interpolation is performed between two resolutions of the Real image. In this paper, the process is explained as a Fade In process.Equalized Learning Rate (runtime weight scaling)The autor said that in order to ensure a healthy competition between Generator and Discriminator, learning at a similar rate is essential and Equalized Learning Rate is suggested approach in this paper. First of all, this method initializes the weight to a value with a range of 0 to 1 in Gaussian Distribution.For all weights, set a same Dynamic range. The reason for doing this is to update the Gradient regardless of the scale of the parameter. When the dynamic range is different for each parameter, it takes a lot of time to adjust the value. Therefore, the author used the Equalized Learning Rate approach to ensure the same learning speed by having the same dynamic range for the parameters of different layers." }, { "title": "Different way of detecting doors and windows", "url": "/posts/FTB-13/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-28 17:13:37 +0900", "snippet": "FloorplanToBlender3DDifferent way of detecting doors and windowsdef find_details()Parameters img : gray scale image of the room, also eroded and doors removed noise_removal_threshold : Minimal area of blobs to be kept corners_threshold : Threshold to allow corners. (Higher removes more of the house) room_closing_max_length : Maximum line length to add to close off open doors. gap_in_wall_threshold : Minimum number of pixels to identify componenet as room instead of hole in the wallReturn returns a list of numpy arrays containing boolean masks for each detected details colored image: A colored version of the input image, where each detail has a random colorFunction Noise is removed from the image Harris Corner Detection is used to detect corners and lines are drawn between corners $\\displaystyle \\boldsymbol{M = \\sum_{x,y} w(x,y) \\begin{bmatrix} I_xI_x &amp;amp; I_xI_y \\ I_xI_y &amp;amp; I_yI_y \\end{bmatrix}}$ $\\displaystyle \\boldsymbol{M} $’s eigen values $\\displaystyle \\boldsymbol{\\lambda_1, \\lambda_2}$ $\\displaystyle \\boldsymbol{ R = \\lambda_1\\lambda_2 - k(\\lambda_1\\lambda_2)^2 }$ The image is inverted and the outside of the hosue is marked as black Connected componenets in the house is found The componenets within the right range is considered as window and doors" }, { "title": "How windows and doors are detected", "url": "/posts/FTB-12/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-25 21:00:45 +0900", "snippet": "FloorplanToBlender3DHow windows and doors are detecteddef feature_match(img1, img2): using cv2.ORB_create() ORB keypoint detector is created keypoints and descriptors of floorplan image and window/door model is created cv2.detectAndCompute keypoints, descriptor is returned pt : coordinates of the keypoint [x,y] size : diameter of the meaningful keypoint neighborhood class_id : object class (if the keypoints need to be clustered by an object they belong to). brute force matcher is created for matching keypoints and descriptors cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) two descriptors are matched together and sorted in distance order from all the matching keypoints from the door model min and max x,y values are calculated the width and the hight of the door model is saved for grouping the matching keypoints in the floor plan from all the matching keypoints from the floorplan the keypoints are grouped if the keypoints distance is smaller than the width and the height of the door model list_grouped_matches = [] is created groups with only one keyoints are deleted because rotation can’t be calculated list_grouped_matches_filtered = [] is created corners of the door is found with cv2.goodFeaturesToTrack() min/max of x and y value is used to find the center(origin) of the door the center(origin) point is used for rotation later " }, { "title": "Changing Output File Format from .blend to .gltb", "url": "/posts/FTB-11/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-23 16:50:11 +0900", "snippet": "FloorplanToBlender3DChange Output file formatThe original output format currently is .blend format. However, for my personal project I need the file format to be in .gltf or .glb because it is easier to open these type of file on mobile. under const.py file change the BASE_FORMAT = &quot;.blend&quot; to BASE_FORMAT = &quot;.gltf&quot; under system.ini file change the out_format = &quot;.blend&quot; to out_format = &quot;.gltf&quot;Then the glb file will be created.However currently the gltf file is not created correctly so it has to be fixed." }, { "title": "Error in Detecting Walls", "url": "/posts/FTB-10/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-21 16:41:21 +0900", "snippet": "FloorplanToBlender3DFinding error in output modelIn the last post there was an issue where some walls were missing in the final blender output file. The reason was found in the ` calculate.remove_walls_not_in_contour() `.The code removes wrongly detected walls which are found outside of the house contour. However, the standard on the wall is too harsh that it deleted some walls which are necessary.Original Code was doing a pointPolygonTest checking if the bouding box of a wall is inside of the outer contour.However I tried doing the pointPolygonTest with bounding box of the outer contour instead of just the outher contour.It seems to have solved the problem.This is before the fixThis is after the fix" }, { "title": "Create Blender Project", "url": "/posts/FTB-9/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-20 16:41:21 +0900", "snippet": "FloorplanToBlender3Ddef create_blender_project data_path which includes txt files are inputed as parameters 3D model is created using information from txt files the output file is originally outputed with .blend file it can be changed to .gltf or other output formatsOuput ExampleAs seen in the image, the walls are correctly madeOutput Error FoundAs seen in the image above, not all of the walls are createdThe reason was found in the ` calculate.remove_walls_not_in_contour() `" }, { "title": "Generate Various Feature Classses", "url": "/posts/FTB-8/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-18 16:41:21 +0900", "snippet": "FloorplanToBlender3Dexecution.pyexecution.pydef simple_single return filepath of a single floorplan it is connected to generate.pygenerate.pydef generate_all_files PARAM floorplan info : whether to save txt file or not world_direction world_scale world_position world_rotation floorplan image is read with IO.read_image() returns: grayscale image, scale_factor(default = 1, if auto-rescaled different value) Various Classes are made from detecting various elements from the floorplan Creates Floor Class Creates Room Class Creates Wall Class Creates Windows Class Creates Door Class JSON txt files including information about each classes are made and saved def generate_transform_file this function creates a transform file containing information about an objects position, rotation PARAM img_path info : boolean if should be printed postion : position vector rotation : rotattion vector shape Return transform " }, { "title": "Blender Python", "url": "/posts/FTB-7/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-13 21:09:52 +0900", "snippet": "Blender Python Floorplan files are added to data_paths The data path is sent to def create_blender_project(data_path) The data path is sent to floorplan_to_3dObject_in_blender.py → def create_floorplan Creates 3D model with blender" }, { "title": "Error installing bpy (2)", "url": "/posts/FTB-6/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-12 15:41:21 +0900", "snippet": "FloorplanToBlender3DFailed to install ‘bpy’Error messageCollecting bpy Using cached bpy-2.82.1.tar.gz (19 kB) Preparing metadata (setup.py): started Preparing metadata (setup.py): finished with status &#39;done&#39;Building wheels for collected packages: bpy Building wheel for bpy (setup.py): started Building wheel for bpy (setup.py): still running... Building wheel for bpy (setup.py): still running... Building wheel for bpy (setup.py): finished with status &#39;error&#39; Running setup.py clean for bpyFailed to build bpyInstalling collected packages: bpy Running setup.py install for bpy: started Running setup.py install for bpy: still running... Running setup.py install for bpy: still running... Running setup.py install for bpy: finished with status &#39;error&#39; ERROR: Command errored out with exit status 1: command: /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/bin/python -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&quot;&#39;&quot;&#39;/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/setup.py&#39;&quot;&#39;&quot;&#39;; __file__=&#39;&quot;&#39;&quot;&#39;/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/setup.py&#39;&quot;&#39;&quot;&#39;;f = getattr(tokenize, &#39;&quot;&#39;&quot;&#39;open&#39;&quot;&#39;&quot;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&quot;&#39;&quot;&#39;from setuptools import setup; setup()&#39;&quot;&#39;&quot;&#39;);code = f.read().replace(&#39;&quot;&#39;&quot;&#39;\\r\\n&#39;&quot;&#39;&quot;&#39;, &#39;&quot;&#39;&quot;&#39;\\n&#39;&quot;&#39;&quot;&#39;);f.close();exec(compile(code, __file__, &#39;&quot;&#39;&quot;&#39;exec&#39;&quot;&#39;&quot;&#39;))&#39; bdist_wheel -d /tmp/pip-wheel-z70fdf6a cwd: /tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/ Complete output (20 lines): running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.7 creating build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/pre_uninstall.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy warning: build_py: byte-compiling is disabled, skipping. running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) Found compatible Blender version 2.82 Cloning Blender source from git (this will take a while) Cloning precompiled libs from svn (this will take a while) cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -S/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/build/temp.linux-x86_64-3.7/blender -B/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/build/temp.linux-x86_64-3.7/build unable to execute &#39;cmake&#39;: No such file or directory error: command &#39;cmake&#39; failed with exit status 1 ---------------------------------------- ERROR: Failed building wheel for bpy ERROR: Command errored out with exit status 1: command: /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/bin/python -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&quot;&#39;&quot;&#39;/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/setup.py&#39;&quot;&#39;&quot;&#39;; __file__=&#39;&quot;&#39;&quot;&#39;/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/setup.py&#39;&quot;&#39;&quot;&#39;;f = getattr(tokenize, &#39;&quot;&#39;&quot;&#39;open&#39;&quot;&#39;&quot;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&quot;&#39;&quot;&#39;from setuptools import setup; setup()&#39;&quot;&#39;&quot;&#39;);code = f.read().replace(&#39;&quot;&#39;&quot;&#39;\\r\\n&#39;&quot;&#39;&quot;&#39;, &#39;&quot;&#39;&quot;&#39;\\n&#39;&quot;&#39;&quot;&#39;);f.close();exec(compile(code, __file__, &#39;&quot;&#39;&quot;&#39;exec&#39;&quot;&#39;&quot;&#39;))&#39; install --record /tmp/pip-record-1xi79tkj/install-record.txt --single-version-externally-managed --compile --install-headers /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/include/site/python3.7/bpy cwd: /tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/ Complete output (20 lines): running install running build running build_py creating build creating build/lib.linux-x86_64-3.7 creating build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/pre_uninstall.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy warning: build_py: byte-compiling is disabled, skipping. running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) Found compatible Blender version 2.82 Cloning Blender source from git (this will take a while) Cloning precompiled libs from svn (this will take a while) cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -S/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/build/temp.linux-x86_64-3.7/blender -B/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/build/temp.linux-x86_64-3.7/build unable to execute &#39;cmake&#39;: No such file or directory error: command &#39;cmake&#39; failed with exit status 1 ----------------------------------------ERROR: Command errored out with exit status 1: /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/bin/python -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&quot;&#39;&quot;&#39;/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/setup.py&#39;&quot;&#39;&quot;&#39;; __file__=&#39;&quot;&#39;&quot;&#39;/tmp/pip-install-cactl59y/bpy_cadc500a6edf4e829fc93157250a95d5/setup.py&#39;&quot;&#39;&quot;&#39;;f = getattr(tokenize, &#39;&quot;&#39;&quot;&#39;open&#39;&quot;&#39;&quot;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&quot;&#39;&quot;&#39;from setuptools import setup; setup()&#39;&quot;&#39;&quot;&#39;);code = f.read().replace(&#39;&quot;&#39;&quot;&#39;\\r\\n&#39;&quot;&#39;&quot;&#39;, &#39;&quot;&#39;&quot;&#39;\\n&#39;&quot;&#39;&quot;&#39;);f.close();exec(compile(code, __file__, &#39;&quot;&#39;&quot;&#39;exec&#39;&quot;&#39;&quot;&#39;))&#39; install --record /tmp/pip-record-1xi79tkj/install-record.txt --single-version-externally-managed --compile --install-headers /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/include/site/python3.7/bpy Check the logs for full command output.WARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.You should consider upgrading via the &#39;/home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/bin/python -m pip install --upgrade pip&#39; command.pip install CmakeCollecting bpy Using cached bpy-2.82.1.tar.gz (19 kB) Preparing metadata (setup.py) ... doneBuilding wheels for collected packages: bpy Building wheel for bpy (setup.py) ... -^[ error error: subprocess-exited-with-error × python setup.py bdist_wheel did not run successfully. │ exit code: 1 ╰─&amp;gt; [49 lines of output] running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.7 creating build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/pre_uninstall.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) Found compatible Blender version 2.82 Cloning Blender source from git (this will take a while) Cloning precompiled libs from svn (this will take a while) cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -S/tmp/pip-install-r8hsv4ez/bpy_e96a69060a9a48959c4491b09072a1a6/build/temp.linux-x86_64-3.7/blender -B/tmp/pip-install-r8hsv4ez/bpy_e96a69060a9a48959c4491b09072a1a6/build/temp.linux-x86_64-3.7/build -- The C compiler identification is GNU 11.2.0 -- The CXX compiler identification is GNU 11.2.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- WITH_DRACO requires WITH_PYTHON_INSTALL to be ON, disabling WITH_DRACO for now -- Performing Test SUPPORT_SSE_BUILD -- Performing Test SUPPORT_SSE_BUILD - Success -- SSE Support: detected. -- Performing Test SUPPORT_SSE2_BUILD -- Performing Test SUPPORT_SSE2_BUILD - Success -- SSE2 Support: detected. -- Found Git: /usr/bin/git (found version &quot;2.34.1&quot;) CMake Error at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:230 (message): Could NOT find JPEG (missing: JPEG_LIBRARY JPEG_INCLUDE_DIR) Call Stack (most recent call first): /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE) /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindJPEG.cmake:106 (find_package_handle_standard_args) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:71 (find_package_wrapper) CMakeLists.txt:804 (include) -- Configuring incomplete, errors occurred! See also &quot;/tmp/pip-install-r8hsv4ez/bpy_e96a69060a9a48959c4491b09072a1a6/build/temp.linux-x86_64-3.7/build/CMakeFiles/CMakeOutput.log&quot;. error: command &#39;cmake&#39; failed with exit status 1 [end of output] note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for bpy Running setup.py clean for bpyFailed to build bpyInstalling collected packages: bpy Running setup.py install for bpy ... error error: subprocess-exited-with-error × Running setup.py install for bpy did not run successfully. │ exit code: 1 ╰─&amp;gt; [49 lines of output] running install running build running build_py creating build creating build/lib.linux-x86_64-3.7 creating build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/pre_uninstall.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) Found compatible Blender version 2.82 Cloning Blender source from git (this will take a while) Cloning precompiled libs from svn (this will take a while) cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -S/tmp/pip-install-r8hsv4ez/bpy_e96a69060a9a48959c4491b09072a1a6/build/temp.linux-x86_64-3.7/blender -B/tmp/pip-install-r8hsv4ez/bpy_e96a69060a9a48959c4491b09072a1a6/build/temp.linux-x86_64-3.7/build -- The C compiler identification is GNU 11.2.0 -- The CXX compiler identification is GNU 11.2.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- WITH_DRACO requires WITH_PYTHON_INSTALL to be ON, disabling WITH_DRACO for now -- Performing Test SUPPORT_SSE_BUILD -- Performing Test SUPPORT_SSE_BUILD - Success -- SSE Support: detected. -- Performing Test SUPPORT_SSE2_BUILD -- Performing Test SUPPORT_SSE2_BUILD - Success -- SSE2 Support: detected. -- Found Git: /usr/bin/git (found version &quot;2.34.1&quot;) CMake Error at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:230 (message): Could NOT find JPEG (missing: JPEG_LIBRARY JPEG_INCLUDE_DIR) Call Stack (most recent call first): /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE) /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindJPEG.cmake:106 (find_package_handle_standard_args) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:71 (find_package_wrapper) CMakeLists.txt:804 (include) -- Configuring incomplete, errors occurred! See also &quot;/tmp/pip-install-r8hsv4ez/bpy_e96a69060a9a48959c4491b09072a1a6/build/temp.linux-x86_64-3.7/build/CMakeFiles/CMakeOutput.log&quot;. error: command &#39;cmake&#39; failed with exit status 1 [end of output] note: This error originates from a subprocess, and is likely not a problem with pip.error: legacy-install-failure× Encountered error while trying to install package.╰─&amp;gt; bpynote: This is an issue with the package mentioned above, not pip.hint: See above for output from the failure.pip install –upgrade pippip install Cmakesudo apt-get install -y libjpeg-devsudo apt-get install libpng-devsudo apt-get install libfreetype6-devCollecting bpy Using cached bpy-2.82.1.tar.gz (19 kB) Preparing metadata (setup.py) ... doneBuilding wheels for collected packages: bpy Building wheel for bpy (setup.py) ... -soerror error: subprocess-exited-with-error × python setup.py bdist_wheel did not run successfully. │ exit code: 1 ╰─&amp;gt; [145 lines of output] running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.7 creating build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/pre_uninstall.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) Found compatible Blender version 2.82 Cloning Blender source from git (this will take a while) Cloning precompiled libs from svn (this will take a while) cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -S/tmp/pip-install-_869nko5/bpy_dc89800be3e348c59990aa8ed4cb59c8/build/temp.linux-x86_64-3.7/blender -B/tmp/pip-install-_869nko5/bpy_dc89800be3e348c59990aa8ed4cb59c8/build/temp.linux-x86_64-3.7/build -- The C compiler identification is GNU 11.2.0 -- The CXX compiler identification is GNU 11.2.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- WITH_DRACO requires WITH_PYTHON_INSTALL to be ON, disabling WITH_DRACO for now -- Performing Test SUPPORT_SSE_BUILD -- Performing Test SUPPORT_SSE_BUILD - Success -- SSE Support: detected. -- Performing Test SUPPORT_SSE2_BUILD -- Performing Test SUPPORT_SSE2_BUILD - Success -- SSE2 Support: detected. -- Found Git: /usr/bin/git (found version &quot;2.34.1&quot;) -- Found JPEG: /usr/lib/x86_64-linux-gnu/libjpeg.so (found version &quot;80&quot;) -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version &quot;1.2.11&quot;) -- Found PNG: /usr/lib/x86_64-linux-gnu/libpng.so (found version &quot;1.6.37&quot;) -- Found Freetype: /usr/lib/x86_64-linux-gnu/libfreetype.so (found version &quot;2.11.1&quot;) -- Found PythonLibsUnix: /usr/lib/x86_64-linux-gnu/libpython3.7m.so -- Could NOT find OpenEXR (missing: _openexr_LIBRARIES OPENEXR_INCLUDE_DIR) -- Could NOT find OpenJPEG (missing: OPENJPEG_LIBRARY OPENJPEG_INCLUDE_DIR) -- Could NOT find TIFF (missing: TIFF_LIBRARY TIFF_INCLUDE_DIR) -- Could NOT find OpenAL (missing: OPENAL_LIBRARY OPENAL_INCLUDE_DIR) -- Could NOT find SDL2 (missing: SDL2_LIBRARY SDL2_INCLUDE_DIR) -- Looking for pthread.h -- Looking for pthread.h - found -- Performing Test CMAKE_HAVE_LIBC_PTHREAD -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success -- Found Threads: TRUE -- Could NOT find SDL (missing: SDL_LIBRARY SDL_INCLUDE_DIR) -- Could NOT find Jack (missing: JACK_LIBRARY JACK_INCLUDE_DIR) -- Could NOT find SndFile (missing: LIBSNDFILE_LIBRARY LIBSNDFILE_INCLUDE_DIR) -- Could NOT find Fftw3 (missing: FFTW3_LIBRARY FFTW3_INCLUDE_DIR) -- Could NOT find OpenCOLLADA (missing: _opencollada_LIBRARIES _opencollada_INCLUDES) -- Could NOT find JeMalloc (missing: JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR) -- Could NOT find Spacenav (missing: SPACENAV_LIBRARY SPACENAV_INCLUDE_DIR) CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (OSL) does not match the name of the calling package (OpenShadingLanguage). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindOpenShadingLanguage.cmake:72 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:244 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find OSL (missing: _osl_LIBRARIES OSL_INCLUDE_DIR OSL_COMPILER) -- OSL not found, disabling it from Cycles CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (OPENVDB) does not match the name of the calling package (OpenVDB). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindOpenVDB.cmake:56 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:262 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find OPENVDB (missing: OPENVDB_LIBRARY OPENVDB_INCLUDE_DIR) CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (BLOSC) does not match the name of the calling package (Blosc). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindBlosc.cmake:56 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:263 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find BLOSC (missing: BLOSC_LIBRARY BLOSC_INCLUDE_DIR) -- OpenVDB not found, disabling it CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (ALEMBIC) does not match the name of the calling package (Alembic). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindAlembic.cmake:54 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:275 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find ALEMBIC (missing: ALEMBIC_LIBRARY ALEMBIC_INCLUDE_DIR) -- Could NOT find Boost (missing: Boost_INCLUDE_DIR filesystem regex thread date_time locale system) (Required is at least version &quot;1.48&quot;) -- Could NOT find Boost (missing: Boost_INCLUDE_DIR filesystem regex thread date_time locale system) (Required is at least version &quot;1.48&quot;) -- Could NOT find OpenImageIO (missing: OPENIMAGEIO_LIBRARY OPENIMAGEIO_INCLUDE_DIR) -- OpenImageIO not found, disabling WITH_CYCLES -- Could NOT find OpenColorIO (missing: _opencolorio_LIBRARIES OPENCOLORIO_INCLUDE_DIR) -- OpenColorIO not found CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (OPENIMAGEDENOISE) does not match the name of the calling package (OpenImageDenoise). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindOpenImageDenoise.cmake:98 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:396 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find OPENIMAGEDENOISE (missing: OPENIMAGEDENOISE_LIBRARY OPENIMAGEDENOISE_INCLUDE_DIR) -- OpenImageDenoise not found -- Could NOT find LLVM (missing: LLVM_LIBRARY) -- LLVM not found -- Could NOT find OpenSubdiv (missing: _opensubdiv_LIBRARIES OPENSUBDIV_INCLUDE_DIR) -- OpenSubdiv not found -- Found TBB: /usr/lib/x86_64-linux-gnu/libtbb.so CMake Error at CMakeLists.txt:815 (message): WITH_MOD_OCEANSIM requires WITH_FFTW3 to be ON -- Configuring incomplete, errors occurred! See also &quot;/tmp/pip-install-_869nko5/bpy_dc89800be3e348c59990aa8ed4cb59c8/build/temp.linux-x86_64-3.7/build/CMakeFiles/CMakeOutput.log&quot;. error: command &#39;cmake&#39; failed with exit status 1 [end of output] note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for bpy Running setup.py clean for bpyFailed to build bpyInstalling collected packages: bpy Running setup.py install for bpy ... error error: subprocess-exited-with-error × Running setup.py install for bpy did not run successfully. │ exit code: 1 ╰─&amp;gt; [145 lines of output] running install running build running build_py creating build creating build/lib.linux-x86_64-3.7 creating build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy copying blenderpy/pre_uninstall.py -&amp;gt; build/lib.linux-x86_64-3.7/blenderpy running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) Found compatible Blender version 2.82 Cloning Blender source from git (this will take a while) Cloning precompiled libs from svn (this will take a while) cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -S/tmp/pip-install-_869nko5/bpy_dc89800be3e348c59990aa8ed4cb59c8/build/temp.linux-x86_64-3.7/blender -B/tmp/pip-install-_869nko5/bpy_dc89800be3e348c59990aa8ed4cb59c8/build/temp.linux-x86_64-3.7/build -- The C compiler identification is GNU 11.2.0 -- The CXX compiler identification is GNU 11.2.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- WITH_DRACO requires WITH_PYTHON_INSTALL to be ON, disabling WITH_DRACO for now -- Performing Test SUPPORT_SSE_BUILD -- Performing Test SUPPORT_SSE_BUILD - Success -- SSE Support: detected. -- Performing Test SUPPORT_SSE2_BUILD -- Performing Test SUPPORT_SSE2_BUILD - Success -- SSE2 Support: detected. -- Found Git: /usr/bin/git (found version &quot;2.34.1&quot;) -- Found JPEG: /usr/lib/x86_64-linux-gnu/libjpeg.so (found version &quot;80&quot;) -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version &quot;1.2.11&quot;) -- Found PNG: /usr/lib/x86_64-linux-gnu/libpng.so (found version &quot;1.6.37&quot;) -- Found Freetype: /usr/lib/x86_64-linux-gnu/libfreetype.so (found version &quot;2.11.1&quot;) -- Found PythonLibsUnix: /usr/lib/x86_64-linux-gnu/libpython3.7m.so -- Could NOT find OpenEXR (missing: _openexr_LIBRARIES OPENEXR_INCLUDE_DIR) -- Could NOT find OpenJPEG (missing: OPENJPEG_LIBRARY OPENJPEG_INCLUDE_DIR) -- Could NOT find TIFF (missing: TIFF_LIBRARY TIFF_INCLUDE_DIR) -- Could NOT find OpenAL (missing: OPENAL_LIBRARY OPENAL_INCLUDE_DIR) -- Could NOT find SDL2 (missing: SDL2_LIBRARY SDL2_INCLUDE_DIR) -- Looking for pthread.h -- Looking for pthread.h - found -- Performing Test CMAKE_HAVE_LIBC_PTHREAD -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success -- Found Threads: TRUE -- Could NOT find SDL (missing: SDL_LIBRARY SDL_INCLUDE_DIR) -- Could NOT find Jack (missing: JACK_LIBRARY JACK_INCLUDE_DIR) -- Could NOT find SndFile (missing: LIBSNDFILE_LIBRARY LIBSNDFILE_INCLUDE_DIR) -- Could NOT find Fftw3 (missing: FFTW3_LIBRARY FFTW3_INCLUDE_DIR) -- Could NOT find OpenCOLLADA (missing: _opencollada_LIBRARIES _opencollada_INCLUDES) -- Could NOT find JeMalloc (missing: JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR) -- Could NOT find Spacenav (missing: SPACENAV_LIBRARY SPACENAV_INCLUDE_DIR) CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (OSL) does not match the name of the calling package (OpenShadingLanguage). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindOpenShadingLanguage.cmake:72 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:244 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find OSL (missing: _osl_LIBRARIES OSL_INCLUDE_DIR OSL_COMPILER) -- OSL not found, disabling it from Cycles CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (OPENVDB) does not match the name of the calling package (OpenVDB). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindOpenVDB.cmake:56 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:262 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find OPENVDB (missing: OPENVDB_LIBRARY OPENVDB_INCLUDE_DIR) CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (BLOSC) does not match the name of the calling package (Blosc). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindBlosc.cmake:56 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:263 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find BLOSC (missing: BLOSC_LIBRARY BLOSC_INCLUDE_DIR) -- OpenVDB not found, disabling it CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (ALEMBIC) does not match the name of the calling package (Alembic). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindAlembic.cmake:54 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:275 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find ALEMBIC (missing: ALEMBIC_LIBRARY ALEMBIC_INCLUDE_DIR) -- Could NOT find Boost (missing: Boost_INCLUDE_DIR filesystem regex thread date_time locale system) (Required is at least version &quot;1.48&quot;) -- Could NOT find Boost (missing: Boost_INCLUDE_DIR filesystem regex thread date_time locale system) (Required is at least version &quot;1.48&quot;) -- Could NOT find OpenImageIO (missing: OPENIMAGEIO_LIBRARY OPENIMAGEIO_INCLUDE_DIR) -- OpenImageIO not found, disabling WITH_CYCLES -- Could NOT find OpenColorIO (missing: _opencolorio_LIBRARIES OPENCOLORIO_INCLUDE_DIR) -- OpenColorIO not found CMake Warning (dev) at /home/frank/PycharmProjects/FloorplanToBlender3d/venv_3.7/lib/python3.7/site-packages/cmake/data/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:438 (message): The package name passed to `find_package_handle_standard_args` (OPENIMAGEDENOISE) does not match the name of the calling package (OpenImageDenoise). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): build_files/cmake/Modules/FindOpenImageDenoise.cmake:98 (FIND_PACKAGE_HANDLE_STANDARD_ARGS) build_files/cmake/platform/platform_unix.cmake:67 (find_package) build_files/cmake/platform/platform_unix.cmake:396 (find_package_wrapper) CMakeLists.txt:804 (include) This warning is for project developers. Use -Wno-dev to suppress it. -- Could NOT find OPENIMAGEDENOISE (missing: OPENIMAGEDENOISE_LIBRARY OPENIMAGEDENOISE_INCLUDE_DIR) -- OpenImageDenoise not found -- Could NOT find LLVM (missing: LLVM_LIBRARY) -- LLVM not found -- Could NOT find OpenSubdiv (missing: _opensubdiv_LIBRARIES OPENSUBDIV_INCLUDE_DIR) -- OpenSubdiv not found -- Found TBB: /usr/lib/x86_64-linux-gnu/libtbb.so CMake Error at CMakeLists.txt:815 (message): WITH_MOD_OCEANSIM requires WITH_FFTW3 to be ON -- Configuring incomplete, errors occurred! See also &quot;/tmp/pip-install-_869nko5/bpy_dc89800be3e348c59990aa8ed4cb59c8/build/temp.linux-x86_64-3.7/build/CMakeFiles/CMakeOutput.log&quot;. error: command &#39;cmake&#39; failed with exit status 1 [end of output] note: This error originates from a subprocess, and is likely not a problem with pip.error: legacy-install-failure× Encountered error while trying to install package.╰─&amp;gt; bpynote: This is an issue with the package mentioned above, not pip.hint: See above for output from the failure." }, { "title": "Error installing bpy (1)", "url": "/posts/FTB-5/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-10 19:06:04 +0900", "snippet": "FloorplanToBlender3DFailed to install ‘bpy’ERROR: Command errored out with exit status 1: command: /home/frank/PycharmProjects/FloorplanToBlender3d/venv/bin/python -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&quot;&#39;&quot;&#39;/tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/setup.py&#39;&quot;&#39;&quot;&#39;; __file__=&#39;&quot;&#39;&quot;&#39;/tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/setup.py&#39;&quot;&#39;&quot;&#39;;f = getattr(tokenize, &#39;&quot;&#39;&quot;&#39;open&#39;&quot;&#39;&quot;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&quot;&#39;&quot;&#39;from setuptools import setup; setup()&#39;&quot;&#39;&quot;&#39;);code = f.read().replace(&#39;&quot;&#39;&quot;&#39;\\r\\n&#39;&quot;&#39;&quot;&#39;, &#39;&quot;&#39;&quot;&#39;\\n&#39;&quot;&#39;&quot;&#39;);f.close();exec(compile(code, __file__, &#39;&quot;&#39;&quot;&#39;exec&#39;&quot;&#39;&quot;&#39;))&#39; bdist_wheel -d /tmp/pip-wheel-rv5h1k5r cwd: /tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/ Complete output (12 lines): running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.8 creating build/lib.linux-x86_64-3.8/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.8/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.8/blenderpy running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) error: [Errno 2] No such file or directory: &#39;svn&#39; ---------------------------------------- ERROR: Failed building wheel for bpy Running setup.py clean for bpyFailed to build bpyInstalling collected packages: bpy Running setup.py install for bpy ... error ERROR: Command errored out with exit status 1: command: /home/frank/PycharmProjects/FloorplanToBlender3d/venv/bin/python -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&quot;&#39;&quot;&#39;/tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/setup.py&#39;&quot;&#39;&quot;&#39;; __file__=&#39;&quot;&#39;&quot;&#39;/tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/setup.py&#39;&quot;&#39;&quot;&#39;;f = getattr(tokenize, &#39;&quot;&#39;&quot;&#39;open&#39;&quot;&#39;&quot;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&quot;&#39;&quot;&#39;from setuptools import setup; setup()&#39;&quot;&#39;&quot;&#39;);code = f.read().replace(&#39;&quot;&#39;&quot;&#39;\\r\\n&#39;&quot;&#39;&quot;&#39;, &#39;&quot;&#39;&quot;&#39;\\n&#39;&quot;&#39;&quot;&#39;);f.close();exec(compile(code, __file__, &#39;&quot;&#39;&quot;&#39;exec&#39;&quot;&#39;&quot;&#39;))&#39; install --record /tmp/pip-record-of4_8nbm/install-record.txt --single-version-externally-managed --compile --install-headers /home/frank/PycharmProjects/FloorplanToBlender3d/venv/include/site/python3.8/bpy cwd: /tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/ Complete output (12 lines): running install running build running build_py creating build creating build/lib.linux-x86_64-3.8 creating build/lib.linux-x86_64-3.8/blenderpy copying blenderpy/post_install.py -&amp;gt; build/lib.linux-x86_64-3.8/blenderpy copying blenderpy/__init__.py -&amp;gt; build/lib.linux-x86_64-3.8/blenderpy running build_ext Preparing the build environment Searching for compatible Blender online (this will take a while) error: [Errno 2] No such file or directory: &#39;svn&#39; ----------------------------------------ERROR: Command errored out with exit status 1: /home/frank/PycharmProjects/FloorplanToBlender3d/venv/bin/python -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&quot;&#39;&quot;&#39;/tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/setup.py&#39;&quot;&#39;&quot;&#39;; __file__=&#39;&quot;&#39;&quot;&#39;/tmp/pip-install-al25lpbe/bpy_13f96a2382624164b6fcb5b3f57e5ff1/setup.py&#39;&quot;&#39;&quot;&#39;;f = getattr(tokenize, &#39;&quot;&#39;&quot;&#39;open&#39;&quot;&#39;&quot;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&quot;&#39;&quot;&#39;from setuptools import setup; setup()&#39;&quot;&#39;&quot;&#39;);code = f.read().replace(&#39;&quot;&#39;&quot;&#39;\\r\\n&#39;&quot;&#39;&quot;&#39;, &#39;&quot;&#39;&quot;&#39;\\n&#39;&quot;&#39;&quot;&#39;);f.close();exec(compile(code, __file__, &#39;&quot;&#39;&quot;&#39;exec&#39;&quot;&#39;&quot;&#39;))&#39; install --record /tmp/pip-record-of4_8nbm/install-record.txt --single-version-externally-managed --compile --install-headers /home/frank/PycharmProjects/FloorplanToBlender3d/venv/include/site/python3.8/bpy Check the logs for full command output.Trial &amp;amp; Solutionsudo apt install subversionHowever bpy doesn’t work on Python 3.8 it only supports Python 3.7Error codeException: 2.82 bpy is not compatible with Linux Python 3.8.13 (default, Apr 19 2022, 02:32:06) [GCC 11.2.0] 64bitSolution Get Python version 3.7 for instructions on how to download the specific version click belowHow to download the specific python version Also get the distutils for python3.7 retry pip install bpy" }, { "title": "Main.py", "url": "/posts/FTB-4/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-09 18:27:04 +0900", "snippet": "FloorplanToBlender3Dmain.py [main] get blender installation path get program path get blender scrip path (Blender/floorplan_to_3dObject_in_blender.py) create_blender_project function gets the floorplan data as a input and makes a blender filemain.py [create_blender_project] gets data paths from main set the output target path floorplan_to_3dObject_in_blender.py is ran with floorplan data as input output file is .blend by default" }, { "title": "Find Details and Match Features", "url": "/posts/FTB-3/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-06 16:55:04 +0900", "snippet": "FloorplanToBlender3DDetect Detail Get gray imagedetect.py[find_details] Param img: gray scale image of rooms, already eroded and doors removed noise_removal_threshold: Minimal area of blobs to be kept corners_threshold: Threshold to allow corners, if higher more of the hosue is removed room_closing_max_length: Maximum line length to add to close off open doors gap_in_wall_threshold: Minimum number of pixels to identify componenet as a room instead of a hole in the wall rooms: List of numpy array of each room detected this function is similiar to fine_room but it detects smaller areas find room had found rooms bigger than 5000 but find_details find rooms (10 ~ 5000)Detect windows and doorsfind_windows_and_doors.py [feature_match] cv2.ORB_create : this is used for finding features in the image ORB is created for original image and door image cv2.BFMatcher : this is used for creating a brute-force matcher bf.match() : this is used for matching original image description and door image description find_windows_and_doors.py [detect_windows_and_doors_boxes] Param img: image of the room door_list : image of a door input image is turned into a gray scale image gray image is used to detect walls with detect.wall_filter() gray image of the wall is used to find rooms and details such as windows and doors detect.precise_boxes is used to get precise boxes of the rooms" }, { "title": "Detect Rooms", "url": "/posts/FTB-2/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-05 17:12:04 +0900", "snippet": "FloorplanToBlender3DDetect Rooms Get wall image and inverse it find_rooms is used to find rooms Rooms are drawn onto the original imagedetect.py [find_rooms] params img:gray scale image of rooms noise_removal_threshold : minimal area of blobs to be kept corners_threshold: threshold to allow corners room_closing_max_length: maximum line length to add to close off open doors gap_in_wall_min_threshold: minimum number of pixels to identify componenet as room instead of hole in the wall return rooms: list of numpy arrays containing boolean masks for each detected room colored_house: a colored version of the input image where each room has a random color image.remove_noise image is filtered (img &amp;lt; 128 = 0, img &amp;gt; 128 = 255) image color is converted and contours are found contourArea greater than noise_removal_threshold (which is 50) is drawn on to the mask mask is returned image.mark_outside_black inverse the image to see the walls of the house get the biggest contour in the img which is the house mask outside of the biggest contour to black return image and mask image: outside of the hosue is black mask: mask of the house cv2.connectedComponenets give each componenets labels check if each componenets is bigger than gap_in_wall_min_threshold (5000px) if bigger it is defined as a room and it is given a random colordetect.py[precise_boxes] image with colored rooms are input contour is drawn areound the room boxes in red" }, { "title": "Detect Contours and Walls", "url": "/posts/FTB-1/", "categories": "FloorPlanToBlender3D", "tags": "study, ftb, opencv", "date": "2022-07-04 15:35:04 +0900", "snippet": "FloorplanToBlender3DDetect ContoursFirst get the ourter contour of the floorplan, in order to create a floor of the 3d object input image convert image from RGB to GRAY detect outer contourdetect.py [outer_contour]s cv2.threshold (230 ~ 255) thresholded image cv2.findContours from thresholded image get the largest contour cv2.approxPolyDP for getting approximage contour with less or same vertices draw contour on the original imageDetect WallsSecond we detect the wall of the floorplan. Filter is used for noise reduction and corner detection.detect.py [wall_filter] filter walls with cv2.threshold with wall threshold values use WALL_FILTER_THRESHOLD range(0, 255) use cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU Finding the background of the image cv2.morphologyEX removes noise from the image leaving only the walls cv2.MORPH_OPEN reduces white color noises cv2.MORPH_CLOSE reduce black color noises cv2.dilate dilates the image when we perform erosion, it removes erosion but it can contract our object dilating the image increases the object area and helps join broken parts of an object Find the foreground of the image cv2.distanceTransform gives inforamtion about each pixel, how far they are from a pixel with 0 value cv2.threshold and dist_transform is used to find the foreground cv2.subtract is used to subtract foreground from background to leave only the walls" }, { "title": "TIL 1 - Error Handling", "url": "/posts/TIL-1/", "categories": "TIL", "tags": "study, python", "date": "2022-06-28 17:31:04 +0900", "snippet": "Today I LearnedError occured while installing python packagesError messageModuleNotFound Error:No module named &quot;distutils.cmd&quot;Solutionsudo apt-get install python3.8-distutils `" }, { "title": "TIL 0 - Environment Setting for Ubuntu 22.04", "url": "/posts/TIL-0/", "categories": "TIL", "tags": "study, ubuntu, python", "date": "2022-06-20 13:11:04 +0900", "snippet": "Enviornment SettingInstall Linux Install Ubuntu 22.04 Use RUFUS for making a USB into a booting USB Partition Scheme : GPT File System : NTFS Go to BIOS setting and boot with USB Install Ubuntu 22.04Install Graphics Driver Check Current Graphics Driver with nvidia-smi Check cuda version with nvcc -V sudo ubuntu-drivers devices to check which driver is recommended sudo apt install nvidia-driver-510 nvidia-driver 510 was recommended for me sudo apt install nvidia-cuda-toolkitInstall Python 3.8 sudo apt install software-properties-coomon -y sudo add apt-repository ppa:deadsnakes/ppa -y sudo apt update sudo apt install python3.8 -yError occured while installing python packagesError messageModuleNotFound Error:No module named &quot;distutils.cmd&quot;Solutionsudo apt-get install python3.8-distutils " }, { "title": "Network - 7", "url": "/posts/Network-7/", "categories": "Computer Network", "tags": "study", "date": "2022-06-15 04:05:14 +0900", "snippet": "Routing Table이 어떻게 만들어지는지Autonomous System 네트워크 관리하는 단위 AS 안에서는 intradomain routing (최단 경로 설정) AS 끼리는 interdomain routing (Rule base 경로 설정)Routing Protocols Intradomain RIP (Distance vector) Link State (OSPF) Interdomain BGP (Path Vector) Bellman-Ford Algorithm i 에서 j 로 가는 최단 경로 구하기 전제 조건: 모든 경로의 거리를 다 안다Distance Vector Routing Table 처음에는 직접 연결된 곳만 cost 작성 그리고 neighbor 한테 table 공유 만약에 A에게 C에서 온 E에 대한 새로운 정보가 들어오면 무조건 업데이트를 해야한다Two-node instability Table을 업데이트 하는 이유 주기적으로 교환 수정이 되면 교환 maximum cost 도달 할때까지 서로 update 한다Solution: maximum cost = 16으로 설정 Split Horizon B 가 A 한테 정보를 받은 뒤로 부터 문제가 발생했다 Next 가 해당인 node 한테는 그 정보를 보내지 말자 ex) B에서 A로 X에 대한 정보만 빼고 보낸다 Split Horizon &amp;amp; Poison Reverse Split Horizon을 적용할시 A는 B가 왜 정보를 안주는 이유를 모른다 Next가 해당인 node 한테는 정보를 보내주기는 하지만 cost 를 $\\infty$로 바꿔서 보낸다 Three node instability 이럴 때는 $\\infty$ = 16 하는 방법 뿐이다Link State Knowledge Dijstra’s AlgorithmDijkstra Algorithm Root node에서 direct로 연결되어있는 것을 후보에 추가 후보군에서 cost 작은거 확정군에 추가 새로 추가된 확정군에서 direct로 연결되어있는거 후보군에 추가 후보군에 destination이 같은게 존재한다면 cost가 낮은것만 남겨놓는다ARPinput : IP 주소output : MAC 주소 Request는 Broadcast로 Local Area Device 한테 모두 보내진다 Reply는 Unicast로 보낸 사람한테 만 간다" }, { "title": "Network - 6", "url": "/posts/Network-6/", "categories": "Computer Network", "tags": "study", "date": "2022-06-15 00:36:41 +0900", "snippet": "Reassembly table Reassemble은 최종 목적지에서만 함 Fragment 하나라도 없어지면 Packet을 다시 보내야함 Fragment를 reassemble 하기 위해 Datagram ID가 필요하다 Time-out : time out이 일어나기 전에 fragment 된 packet이 안들어오면 모두 다 버림Problem TCP를 너무 크게 만들면 fragment가 만아지면서 packet loss가 생길 시 인식하는데 시간이 너무 오래 걸린다ICMP IP header = Destination이 들어감 (위 그림에서 는 A가 들어간다) ICMP meassage = 에러 종류 에러가 생기면 source 한테 보고를 한다ICMP message type, code로 어떤 에러인지 알 수 있다ICMP packet 어디에서 어떤 에러가 누구한테 가려고했던 어떤 애플리케이션으로 가려고 했던 어떤 패킷에서 오류가 생겼다Destination-unreachable errorType : 3Code: 0 ~ 15 Code 4 : (Fragmentation Required but DF bit is set) MTU가 작은 네트워크를 통과하기 위해 fragment를 해야하는데 DF 설정이 되어있어서 오류 폐기 Code 3 : (Port Unreachable) 목적지 호스트에서 특정 포트번호가 사용될 수 없음을 알림 Code 0 : (Network Unreachable) 디폴트 라우트가 없을 경우 + 라우팅 테이블에 목적지 주소가 없을 경우IP 쪽에서는 flow control을 담당하지 않는다 (그 쪽은 TCP 쪽에서 )Source-Quench message 혼잡에 의한 패킷(datagram)이 버려진 상황을 source 한테 알린다Time-Exceeded messageCode 0 Router가 패킷을 받을 때마다 TTL에 -1 을 해준다 if TTL == 0 버리고 source 한테 알린다Code 1 정해진 시간안에 모든 packet이 들어오지 않았음을 source 한테 알린다Parameter-Problem Message Header에 문제가 있을 때 packet을 버리고 알린다 ICMP header에 pointer가 존재해서 header에 어디에 문제가 있는지 알려준다Redirection Concept Redirection Message를 통해 더 짧은 길을 알려준다 그걸 통해서 routing table이 업데이트 된다 ICMP header에 새로운 target router의 IP 주소를 작성한다Echo-request and echo-reply message 상대방 컴퓨터의 Network layer까지 갔다온다 Request를 보내면 Reply를 보내준다Timestamp-request and Timestamp-reply message 처음 출발 시간 → Original timestamp 받은 시간 → Receive timestamp 다시 보내는 시간 → Transmit timestampTraceroute program operation TTL을 하나 씩 늘려서 돌아오는 ICMP를 보면서 router들을 trace 할 수 있다" }, { "title": "Network - 5", "url": "/posts/Network-5/", "categories": "Computer Network", "tags": "study", "date": "2022-06-14 22:05:03 +0900", "snippet": "Network Layer 의 Packet = DatagramTotal Length header + data의 전체 길이 전체 길이를 알아야 padding이 얼마나 되는지 알수있다TTL (Time to Live) Maximum Hop Count if 0 packet 버린다Protocol 1 = ICMP 2 = IGMP 6 = TCP 17 = UDP 89 = OSPF Packet을 받을 때 상위 layer에서 온게 TCP 인지 UDP인지 확인 Packet을 보내는 입장이면 보낼 때 TCP로 보낼지 UDP로 보낼지 알려준다Fragmentation frame 안에 들어가는 payload minum = 46 payload maximum = MTU only data in a datagram is fragmentedFlag D : Do not fragment M : More fragments M = 1 이면 뒤에 더 fragments가 남아있다 M = 0 이면 마지막 fragment이다Fragmentation Offsets Offset = Fragment 시작 바이트 번호 / 8 ex) 1400 ~ 2799 → offset = 1400 / 8 = 175 MTU는 datagram의 max 크기인데 header + data의 크기 이므로 ex) MTU = 1420byte 이면 1400 byte로 fragment 하겠다는 것이다 ex) Offset value = 100, HLEN = 5, Total length field = 100, what is the first and the last byteA) first byte = 100 * 8, header = 20 byte, last byte = 879Option option format Single-byte No operation End of option Multiple-byte Record route Strict Source route Losoe source route Timestamp Record-route concept option number : 7 15 : total length pointer router 에서 나가는 주소를 기록한다 Packet이 어떤 route를 거쳐왔는지 알 수 있따Strict Source Route option option number : 137 가는 경로를 미리 packet에 써놓은다 router로 들어가는 주소를 기록한다 그래야 destination 정보로 사용할 수 있다 Destination 과 pointer가 가르키는 주소와 switch 하면서 이동한다 누가 보냈고 어디 어디를 거쳐서 왔는지 볼 수 있다 Next Destination이 없으면 packet을 버린다 순서 엄수 네트워크 관리용으로 사용한다Loose-source-route option option number : 131 순서가 달라도 상관없다Timestamp Concept record route 와 비슷하지만 시간까지 기록한다네트워크 설정 시 꼭 설정 해야할 것: IP 주소 Subnet Mask Next Hop (router 주소) DNS 서버주소DNS server input : domain name output : IP addressChecksum IP header 안에있는 checksum은 ip header 만 확인gksek TCP header에 있는 checksum은 data 까지 확인한다" }, { "title": "Network - 4", "url": "/posts/Network-4/", "categories": "Computer Network", "tags": "study", "date": "2022-06-14 19:42:37 +0900", "snippet": "Multiprotocol Label Switching (MPLS) high speed IP forwarding using fixed length label MPLS forwarding tables labeling 해서 forwarding 한다Web &amp;amp; HTTP hypertext transfer protocol Web’s application-layer protocol client : request 보내는 쪽 server : request 받고 response 보내는 쪽 TCP 를 사용한다 reliability 걱정 안해도 된다 server는 port 80번 사용한다 browser (HTTP client) and Web Server (HTTP server) HTTP is “stateless” = 과거 request 저장 안한다Non-persistent HTTP 1.0 object 하나당 2 RTT 가 걸린다 1 RTT = TCP connection 1 RTT = HTTP request and response FCFS 방식이여서 큰 object 요청이 들어오면 그 뒤에 object이 느리게 간다 object 별로 TCP 연결Persistent HTTP 1.1 server leaves connection open after sending response pipelining : sends requests right away, reponse 받기 전에 request 또 보낸다HTTP request message POST method GET methodHTTP response status codes 200, 301, 400, 404, etcHTTP 2 Object divided into frames" }, { "title": "Network - 3", "url": "/posts/Network-3/", "categories": "Computer Network", "tags": "study", "date": "2022-06-14 15:12:58 +0900", "snippet": " classless 에서는 뒤에 / n 을 꼭 써줘야한다Special AddressLoopback address 127.x.y.z 네트워크 실험할때All-zero address 0.0.0.0 유동 IP를 할당해주는 protocol = DHCP Protocol DHCP Server가 유동 IP를 준다 일반 컴퓨터가 DHCP 한테 보낼 때 all-zero address를 사용된다Broadcast AddressLimited BroadCast 255.255.255.255 네트워크 모두한테 protocol을 보낼 때 router에서 나가는걸 restrict 해서 limited라고 불린다Limited Broadcast suffix가 모두 1이다 router가 한쪽 네트워크한테 모두 보낼 때 사용Private Networks 192.168.0.0/16 10.0.0.0/8 172.16.0.0/12 169.254.0.0/16NATnetwork address translation사설망 사용할 때 필요하다 NAT translation table Computer sends request to router S : 10.0.0.1 , 3345 D : 128.119.40.186 , 80 NAT translation table changes the IP and Port number and record S : 138.76.29.7, 5001 D : 128.119.40.186 , 80 Package returns S : 128.119.40.186 , 80 D : 138.76.29.7 , 5001 NAT translation table translate it and router sends it back S : 128.119.40.186 , 80 D : 10.0.0.1 , 3345 Port Forwarding랑데뷰 서버위에 기술이 : Hole punchingDeliveryDirect Delivery Computer → Computer Router → Computer Switch : FilteringIndirect Delivery 같은 네트워크에 없을 때 router를 통해서 다른 네트워크로 보낼때 Computer → Router Router → RouterForwarding packet을 next hop으로 보내는 것Next-hop method Routing table based on route 모든 경로를 저장해야하기 때문에 비효율적 based on next hop 다음 hop만 기록한다 Network-specific method 모든 주소를 다 적지 않고 대표적인 네트워크 주소만 적는다 Host-Specific으로 적으면 너무 많아 질 수 도 있다Host Specific Routing routing table에 specific 하게 destination에 host 주소가 적혀있다Default Routing routing table에 해당된 주소가 없으면 Default Route로 보낸다Forwarding module in classful address Class 별로 Routing Table 만든다 Subnet 있으면 Subnet Mask를 적용시켜 table을 본다 Destination Next Hop Interface Forwarding module in classless address Mask Destination Next Hop Interface 목적지 주소가 들어오면 Mask와 AND를 해서 Network Address에 있는지 확인한다IP Header에 들어가있는 IP 주소와 별개로 router들이 routing table을 관리한다Address Aggregation Network 주소가 겹치면 하나로 줄일 수 있다Longest Mask Matching 가장 긴 마스크를 가진 애를 맨 위에 놔둔다 Address Aggregation의 상위 버전" }, { "title": "Network - 2", "url": "/posts/Network-2/", "categories": "Computer Network", "tags": "study", "date": "2022-06-14 02:59:32 +0900", "snippet": "TCP timersPersistence Timer 교착상태를 해결하기 위하여 사용 영속타이머가 만료되면, probe segment 전송Keepalive Timer 오랜 기간 동안 idle 상태에 있는 것 방지 서버가 2시간 동안 클라이언트로부터 세그먼트를 전송 받지 못하면, probe 세그먼트 전송RTO 계산 방법 TCP는 RTT를 측정한다 RTO = RTTs + 4 * RTTd RTTs = (1 - $\\alpha$) RTTs + $\\alpha$ RTTm $\\alpha$ = 1/8 RTTd = (1 - $\\beta$) RTTd + $\\beta$ ** ** RTTs - RTTm $\\beta$ = 1/4 OptionMaximum-segment-size option default 대략 500 byte Segment size 바꿀수있다 바꾸기 위해서 이 옵션 사용한다Window-scale-faction option rwnd를 사용해서 16비트 사용 RTT는 줄여서 데이터 전송률을 scale하기 위해 사용SACK Packet이 어떻게 보내졌는지 모르기 때문에 뭐를 못 받았고, 그 뒤에 어떤것들을 못받았는지 알려준다IPv4 32 비트 ip 주소는 전세계에 하나밖에 없다 (사설만 예외 192.168. , 127. )\\ 32 bits를 byte 단위로 나눠서 10진법 으로 표현해서 나타낸다.10000000 = 12811000000 = 19211100000 = 22411110000 = 240Classful Addressing Class A = $2^{31}$ Class B = $2^{30}$ Class C = $2^{29}$ Class D = $2^{28}$ Class E = $2^{28}$Class A : 0 ~ 127Class B : 128 ~ 191Class C : 192 ~ 223Class D : 224 ~ 239. (Multicast Address)Class E : 240 ~ 255 (Reserved for future use)시작 주소 : Network address끝 주고 : Broadcast 용도 Router는 양쪽에서 주소를 할당 해준다 Routing Table에는 Network Address(목적지 주소), Next Hop이 어떤 interface에 연결되어있는지 적혀있다 Routing Table에 Network id (시작주소) 만 들어가있다 Network Address 를 구하기 위해 Network Mask를 주소와 AND operation을 한다 결과적으로 Network id 만 남고 Host id는 다 날라간다 Sub NetworkingSubnet Mask : network mask + $log_2 (subnet \\space size)$" }, { "title": "Network - 1", "url": "/posts/Network-1/", "categories": "Computer Network", "tags": "study", "date": "2022-06-13 14:22:03 +0900", "snippet": "RTO 처음에는 초기값 그 다음 부터 RT0 = RTTs + 4 * RTTdRTT 처음 RTTs = RTTm 다음 RTTs = (7/8)RTTs + (1/8)RTTmRTT Deviation 처음 값 없음 첫 번째 이후 RTTd = RTTm / 2 다음 = (3/4)RTTd + (1/4) RTTs - RTTm Karn’s Algorithm 재전송 되는 packet에 대한 RTT를 업데이트 하지 말자 RTO = RTO * 2TCP optionEnd-of-option 빈칸 채우기 용No-operation option 빈칸 채우기 용Maximum-segment-size MSS 초기 연결 때 Size 크기를 바꿀 수 있다Window-scale-factor option Window size = min (rwnd, cwnd) 초기 연결 설정 때만 가능Timestamp option ACK에 출발 시간을 적어준다 그걸 가지고 RTT를 계산할수있음SACK 받은것이 어디서 부터 어디까지다를 알려 준다 없어진 packet 뒤로 다 보낼 필요 없이 없어진것 만 보낼 수 있게 해준다" }, { "title": "AI Review", "url": "/posts/AI-6/", "categories": "AI", "tags": "study", "date": "2022-06-08 14:19:47 +0900", "snippet": "AI Engineering + Science : 사람과 동물을 연구해서 지능이 어떻게 작동하는가 를 컴퓨터에 적용Symbolic AI vs Connectionist AISymbolic AI : Rule로 만들어서 결정을 내린다, Rule을 만드는게 시간이 오래걸린다, data issue 보다 rule issue가 더 크다 사람이 rule을 만든다 Rule이 모이면 knowledge가 된다 Sementic Web에서 triple로 만들어놔서 data 공유 가능 결과는 : knowledge graphConnectionist AI (Neural Net) : Data를 이용해서 training을 해서 network를 학습 시켜 (weight를 업데이트를 시켜서) prediction을 한다 사람이 data를 만든다 data driven network이다 data에 annotation 해야한다 결과는 : 학습된 network학습(Training) 가중치를 업데이트를 해서 error를 줄여서 prediction 정확도를 높이려는 것이다WATSON : 음성인식 : Neural Network 정답 찾기 : Symbolic AISupervised Learning : Data를 가지고 error를 구해 그 값을 다시 input으로 넣어서 하는것 거의 classification이다Unsupervised Learning: Data mining과 같이 데이터만 주어지고 스스로 판단한다CNN exact matching 방법은 비효율적이고 정확도가 매우 낮다 pattern, feature를 뽑아내서 비교한다prediction은 완벽할 수 없다True positive, False Positive, False Negative, True Negative 뜻 다 알아야하고 해결 방법도 알아야한다" }, { "title": "AI Vision - Workplace Saftey", "url": "/posts/AI-5/", "categories": "AI", "tags": "study", "date": "2022-06-06 15:13:12 +0900", "snippet": "AI 시각 지능 - 산업 안전 응용sAI Computer 가 ‘Think’ 하고 판단 Computer 가 사람 처럼 보고 듣고 그리고 말하기AI 딥러닝의 응용 물체인식, 이미지 분류, 이미지 분할 물체 추적 비디오 이해산업 안전 AI 학습용 데이터 및 이상 객체 탐지 항공 활주로 내 이상 물체 감지를 위한 객체 데이터 공사현장 안전장비 인식 데이터 화제 발생 예측 데이터산업안전 AI 학습inference : 추론False Positive, False Negative를 해결해야한다SI : Sytem IntegrationSymbolic AI vs Neural AI Link, Triple들을 기계적으로 knowledge graph 생성 Closed World Assumption흑백 논리: 내가 아는것은 true, 내가 모르는것은 false 이다 Open World Assumption True, False, Unknown " }, { "title": "CNN", "url": "/posts/AI-4/", "categories": "AI", "tags": "study", "date": "2022-06-06 02:46:59 +0900", "snippet": " 이미지와 같은 경우에는 exact matching으로 classify하는것이 어렵다 translation, scaling rotation, weight가 적용이 되면 매우 어려워진다 ConvNet it matches pieces of the image instead of exact matching features를 이용해서 matching을 한다 Filtering if 문을 이용해서 matching을 하면 매우 오래 걸리기 때문에 행렬 계산으로 한다 Pooling maximum value를 뽑아낸다 ReLU (Rectified Linear Units) negative values → 0 Deep Stacking hidden layer를 쌓는다 Fully Connected layer every value get a vote Symbolic AI는 logic을 따르기 때문에 True, False로 확실하게 나온다Non-Symbolic AI는 classification이 틀릴수도 있다AI prediction = Classification Classification은 seperator를 정하는 것이다 과거의 데이터로 미래의 데이터를 예측 할 수 있다False Positive : 맞다고 판단했는데 실제로 아닌 경우False Negative : 아니라고 판단했는데 실제로 맞는 경우HyperparametersConvolution Number of features Size of featuresPooling window size window strideFully Connected Number of neuronsArchitecture: 모델 설계, how many of each type of layer? in what orderData Augmentation : 데이터 수를 늘리기 위해 데이터를 수정한다Domain Knowledge : ex) 현장에 대한 기본 지식공공 데이터: classify 된 데이터" }, { "title": "How to train the model", "url": "/posts/AI-3/", "categories": "AI", "tags": "study", "date": "2022-06-05 19:27:10 +0900", "snippet": "Gradient DescentE = T - AT = Target OutputA = Network Output error 함수가 continuous 한 것을 원한다 optimize with respect to [ ] → [ ] 에 대해서 optimize 해라 [ ]을 이용해서 최소화 하기 위해서 weight 값을 조정해라 목적함수, optimizer function : error를 낮추려고 한다 minimum에 도달하면 error가 최소화 되며 예측도 잘 된다\\[{\\delta E \\over \\delta W } = -(e_j) \\cdot sigmoid(\\sum W \\cdot O) ( 1 - sigmoid(\\sum W \\cdot O)) \\cdot O\\]\\[new \\space W = old \\space W - \\alpha \\cdot {\\delta E \\over \\delta W }\\]" }, { "title": "Introduction to NN Chapter 2", "url": "/posts/AI-2/", "categories": "AI", "tags": "study", "date": "2022-06-04 20:07:18 +0900", "snippet": "XOR problem can’t be solved with just a single linear classifier so multiple nodes are neededBrains in Nature Brains in Nature can do sophisticated things and they are resilient Neurons are all connected and send signals 뉴런이 더 자주 사용하면 strong 해진다Neurons are activated when the signal is over the threshold Digital → Analog으로 변환하기 위해서 Sigmoid 함수 사용 $y = 1/(1 + e^{-x})$ Weight are adjustable parameters 초기 weight는 random 값이다 Data를 학습시키는 것은 weight 조절하는 것이다Gradient descent is a practical way of finding the minimum of difficult functionsYou can avoid overshooting by talking smaller steps which is smaller learning rateData를 가지고 학습한다는 뜻은 weight를 tuning한다는 뜻이다데이터의 편협성: 학습은 주어진 데이터로만 하기 때문에 잘못된 방향으로 학습이 될 수 있다" }, { "title": "Neural Network", "url": "/posts/Neural_Network/", "categories": "Machine Learning", "tags": "study", "date": "2022-06-04 17:05:32 +0900", "snippet": "Deep Learning XOR 문제 해결 Perceptron : 신경망의 최소 단위 Input → weighted sum → activation function → output Back propagation (오차 역전파) 가중치 초기화 (Random initialize) 순전파를 통한 출력값 계산 비용 함수 (cost function) 정의 및 1차 미분식 구하기 역전파를 통한 1차 미분값 구하기 파라미터 (Parameter) 없데이트 (2) ~ (6) 과정 반복3. 비용함수 정의 및 1차 미분식 구하기 $1 \\over 2$가 들어가는 이유는 미분 할 때 의 편의성을 위해서 추가됐다 Sigmoid 함수는 계산의 편의성을 준다4. 역전파를 통한 1차 미분값 구하기 역전파에서는 가중치나 편향이 변했을 때의 출력값의 변화를 구하기 위해서 미분을 한다5. 파라미터 업데이트 학습률 Hyperparameter 경사 하강법 (Gradient Decent) 최소 제곱법을 사용해서 정답과 예측 사이의 거리를 줄였었다 머신러닝에서의 최적화 문제 최적화 목적 함수인 손실 함수의 미분값을 이용하는 방법 초기 모델 파라미터 $\\theta_1$에 해당하는 목적함수 $J(\\theta_1)$의 미분값을 구한다 1에서 구한 미분값의 반대 방향으로 $\\theta_1$을 $\\nabla J(\\theta_1)$ 만큼 이동시킨다 (학습률 적용)$\\theta_{t+1} = \\theta_{t} + \\Delta\\theta_{t} \\ \\ \\Delta\\theta_{t} = -\\eta \\nabla J(\\theta_{t})$ 1, 2 단계를 반복한다 모든 데이터를 확인해서 경사 하강법을 계산하기 때문에 데이터가 클 수록 학습 시간이 길어짐확률적 경사 하강법 (Stochastic Gradient Decent) 일반적인 배치 경사하강법은 데이터 증가에 따라 최적해를 찾는 시간이 길어진다 확률적 경사 하강법: 경사 하강법의 샘플링 기법, 전체 데이터에서 추출한 샘플 트레이닝 데이터를 사용해 최적해를 찾음 모든 데이터를 다루는게 아니기 때문에 학습률이 잘못될수도 있다코드 퀴즈 예제)cross validation의 장단점cross validation을 극복하기 위한 방법" }, { "title": "Introduction to NN Chapter 1", "url": "/posts/AI-1/", "categories": "AI", "tags": "study", "date": "2022-06-02 19:49:47 +0900", "snippet": "AIAI and MetaverseVR: 현실과 유사한 체험을 할 수 있도록 구현된 가상의 공간AR: 현실에 3차원 가상 이미지를 겹쳐서 보여주는 기술MR: 현실과 홀로그램을 겹쳐서 보여주는 기술로 여러 사람이 공유하여 볼 수 있음IoT with AI node = thing node is connected to each other MS Holoens : MR Car : computer with wheelsMR : Virtual and Real world 같이 보여서 Mixed reality 이다Metaverse 가상, 초월 (Meta) + 세계, 우주 (Universe)의 합성어 증강현실 라이프 로깅 거울 세계 가상 세계XR 기술의 산업화 digital contentIoT 기반의 인공지능 Google Home Amazon KIVA HoloLens 무인항공기Digital Twin Technology for liking AI and knowledge Object recognition and tracking technology다가올 미래 - Metaverse 3D Web + AI Metaverse 세상 → 차세대 먹거리 변화의 속도와 새로운 환경에 맞는 새로운 기업 육성 필요Introduction to NN Chapter 1Human vs MachineHuman: Recognize people in this photoComputer Vision: It acts as computer’s eyes + adding numbersSimple Predicting Machineinput -&amp;gt; process -&amp;gt; outputModel : input 값에 parameter를 곱해서 output을 만들어낸다 Classifying is not very different from Predicting ex) 가격이 오를 주식, 가격이 떨어질 주식 이런 형식으로 classifying 도 가능하기 때문에 이를 통해 predict를 할 수 있다Training a simple classifier 과거의 data를 통해 현재와 미래의 input data를 받아 predict 한다Learning from Data Learning = parameter update = shifting, adjusting 하는 과정이다 Data의 근간을 찾아서 prediction을 한다 Learning의 결과로 분류자, 구분자가 나온다 $\\Delta = T - A \\T = ground \\space truth \\ A = model \\space output$ 변화만큼 기울기가 움직인다 $E = Target - Actual \\ E = Error \\ E = (A + \\Delta A)x - Ax \\ \\Delta A = E/x$ Supervised Learning 기울기 update를 조절하기 위해 learning rate가 곱해진다 $\\Delta A = L \\cdot(E/x)\\L = learning\\space rate$ outlier 때문에 learning rate을 작게 잡아야한다 Classification이 Prediction과 같은 이유 모르는 현재 또는 미래의 새로운 데이터를 과거의 데이터를 바탕으로 classify 하기 때문에 predict와 비슷하다Supervised Learning : 데이터를 가지고 뭐가 맞다 틀리다를 통해 에러를 구해서 계속 training 을 찾는다Unsupervised Learning: Data mining 같이 데이터를 수백만개를 줘서 스스로 rule을 찾도록 한다" }, { "title": "Unsupervised Learning - 2", "url": "/posts/Unsupervised_Learning-2/", "categories": "Machine Learning", "tags": "study", "date": "2022-06-02 15:21:46 +0900", "snippet": "Kernel 함수는 내적으로 표현이 가능하다 차원 확대가 가능하다독립 성분 분석 (Independent Component Analysis, ICA) Cocktail party problem을 해결 할 때 사용되는 알고리즘이다\\[x = As \\\\ s = A ^ {-1} x = Wx \\\\ s = source \\space , \\space x = recorded \\space sound\\] A: 혼합 행렬 A를 알아내기 위해 Independent Component Analysis를 한다 중심극한정리 : n개의 확률변수들의 선형결합으로 만들어진 확률변수는 가우시안 분포를 따른다( n → 무한대 ) 이면 더욱더 가우시안을 따른다대우명제: 정규분포를 따르지 않는 n개의 확률분포들이 independent(non-gaussian) 하다 ICA는 정규분포화 되어있는 것을 서로 다른 독립된 확률 변수로 나누려고 한다 역행렬구하는 계산은 매우 어렵다 —&amp;gt; 역행렬을 없애려고 해야한다Non-negative Matrix Factorization (NMF)Non negative 의 장점 역행렬 계산시 편리함 이미지 데이터 처리 시 음영 표시가 편리함 0 ~ $\\infty$ 필요없는 데이터를 0으로 보낸다t-SNE (Stochastic Neighbor Embedding) t 분포 (가우시안 분포 아님) 가우시안 분포 보다 t 분포 기울기가 더 낮기 때문에 error가 줄어든다 Neighbor Embedding : 고차원에서 저차원으로 Data를 보낼 때 유사성 유지 Stochastic한 이유 : 기준점을 random으로 잡기 때문" }, { "title": "Reinforced Learning", "url": "/posts/Reinforced_Learning/", "categories": "Machine Learning", "tags": "study", "date": "2022-06-01 17:07:04 +0900", "snippet": "강화 학습 어떻게 상호작용을 하는가가 중요하다 경험을 중요시한다 (trial &amp;amp; error) perception $\\uparrow$ , cognition $\\uparrow$ → 판단력 $\\uparrow$ 과거의 경험을 기반으로 현재의 나의 knowledge $\\uparrow$ 벽돌깨기 Agent: computer or machine Environment: Game State: Current game state Action: Moving the bar Reward: Score Policy: 판단력 policy를 올바르게 세워 나가는 과정Policy : 더 많은 reward를 받기 위해서 고민한다, function의 형태로 존재, 강화학습에서의 Kernel Model-Based RL : 환경에 대해 이미 정보를 다 가지고있다 Model-Free RL : 환경에 대한 정보가 없을 때 Agent가 Action을 통해서 Reward를 최대로 받도록 하는게 Policy function을 통해 하는것이다Model Based RLMarkov Decision Process (확률) Markov Process $\\subset$ Random Process Random Process : 시간의 진행에 따라 상태가 확률적으로 변화함 Markov Process : Markov 속성을 가지는 Random process Agent does action and it affects the environment and changes its state and gives a reward back to the agent 위와 같은 “closed-loop”을 만들어야한다 State 0 ~ State t 까지 가서 State t+1에 도달할 확률은 State t에서 State t+1에 도달할 확률과 똑같다 순차적인 결정을 내리는것이 강화학습임 강화학습에서 최종 목표는 Policy를 최대화 하는것 → State를 도달할때 마다 Policy를 최대화 하면서 Action을 취한다 State t —policy—&amp;gt; Action —reward—&amp;gt; State t+1 State → Action : State value function Action → State : Action value functionBellman Equation State-Value function &amp;amp; Action-Value function 의 관계 현재의 state/action 과 다음 state/action과의 관계식 Dynamic Programming의 한 종류이다 Markov와의 차이점은 Markov는 바로 직전 state만 신경 쓰지만 Bellman은 모두 기억하면서 활용을 한다 재귀 vs DP time complexity 차이가 매우 크다 재귀는 여러번 call 해야하지만 dp는 한번에 가져온다 Monte-Calro Methods Model-based DP는 계산 복잡도의 한계로 실제 문제에 적용 불가능 Model-free : 환경을 모르기 때문에 확률로 접근한다 Monte-Carlo Method: 무한이 여러번 Sampling 하면 한 특징을 그려낼 수 있다 여러번 Sampling 하면서 특징이 결국에는 수렴을 해야하기 때문에 MCMC 사용 넓은 search space를 Markov Chain을 사용해서 space를 줄인다 Recap지도 학습 vs 비지도 학습 훈련데이터에 타깃 유무머신러닝의 학습 과정 데이터로부터 특성 데이터와 타깃 데이터의 관계, 패턴을 학습하여 분류 혹은 예측 파라미터가 최적화 되는 과정에서 특정이 만들어진다학습이 잘 되기 위해 훈련 데이터와 테스트 데이터를 나눠야한다 테스트 데이터는 훈련 데이터에 들어가면 안된다 → 예측이 아니라 기억이다 Cross-Validation : 교차적으로 Train / Validation 세트를 나누어 가며 모델의 학습 정확도 평가 train data가 validation에 들어가서 검증을 오염시키면 안된다 시계열 데이터 (Time series) Sliding Window를 사용해서 data augmentation을 하기 때문에 데이터 중첩이 일어난다 Train 과 Validation이 자주 겹친다 error가 자주 일어난다 A : 나는, C : 기계, B: 나는 기계 사이 문제가 생긴다 결정계수 (Coefficient of determination, $R^2$): 회귀의 정확도를 표현 $R^2 = 1 - {(타깃 - 예측)^2의\\space 합 \\over (타깃 - 평균)^2 의 \\space 합}$고 과대적합과 과소적합 확인 가능 Accuracy의 한계: Positive만 물어본다, class imbalance를 알아내기 어렵다1종 오류: 실제 효과가 없는데 효과가 있다고 나타내는 것2종 오류: 실제로 효과가 있는데 효과가 없다고 하는 것Precision / RecallPrecision : 정밀도 (내 모델이 positive하게 예측한것 중에 실제로 positive 한 것)Recall : 재현율 (positive data 중에서 내 모델이 얼마나 positive 하게 예측했나)F1 Score = 2 x ${recall \\times precision} \\over {recall + precision}$mAP (ROC 와 연관되어있음 PR과 차이도 봐야함) x축: recally축: precision그래프가 그려진 curve의 면적Receiver Operating Characteristic (ROC) Curve 이진 분류 시스템의 성능 평가 기법 True Positive Rate = Sensitivity = Recall False Positive Rate = Specificity = Precision True Positive Rate $\\uparrow$ &amp;amp; False Positive Rate $\\downarrow$ ROC curve는 True Positive Rate 과 False Positive Rate의 관계 ROC curve 위의 점은 Threshold 값에 대한 TPR과 FPR의 관계 Curve가 클수록 좋다PR curve vs ROC curve PR : 세부적이다ROC : generative" }, { "title": "Unsupervised Learning - 1", "url": "/posts/Unsupervised_Learning-1/", "categories": "Machine Learning", "tags": "study", "date": "2022-06-01 12:04:04 +0900", "snippet": "K-Means Clustering 무작위로 K개의 클러스터 중심을 정함 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플로 지정 클러스터에 속한 샘플의 평균값으로 클러스터 중심을 변경함 클러스터 중심이 변화가 없을 때 까지 2번으로 돌아간다 최적의 k 찾기 엘보우 (elbow 방법을 사용해서 최적의 K 찾음) K-평균: 클래스별 클러스터의 중심을 반복적으로 계산 하면서, 최적의 클러스터를 구성하는 알고리즘 클러스터 중심: K-means algorithm을 통해 만들어진 클러스터에 속한 샘플의 특성 평균값 엘보우 방법: 최적의 클러스터 개수를 정하는 방법 중 하나from sklearn.cluster import KMeanskm = KMeans(n_clusters = 3, random_state, init=&#39;random&#39;, max_iter=100)km.fit(X,y)label_km = kmc.labels_print(kmc.labels_)# km_inertia_ : inertia value 계산# inertia = 클러스터 중심과 샘플 사이 거리의 제곱함차원 축소 알고리즘 차원을 축소하는 이유: 데이터에는 중요한 부분과 중요하지 않은 부분이 존재 차원 축소: 데이터의 중요하지 않은 부분을 제거 차원의 저주 데이터의 차원이 커질수록 해당 차원을 표현하기 위해 필요한 데이터가 기하급수적으로 많아짐 주성분 분석 (Principal Component Analysis) 행렬이 주어짐 → 무언가 특별함을 찾고싶다 → 고유값 고유벡터 구해야함 여러 특성이 통계적으로 서로 상관 관계가 없도록 변환 데이터에 있는 분산이 큰 방향을 찾는 것 (데이터를 잘 표현하는 벡터) 공분산 행렬에서 고유값과 고유벡터가 중요하다\\[\\begin{bmatrix} x축 &amp;amp; x \\cdot y \\\\ x \\cdot y &amp;amp; y축 \\end{bmatrix}\\] 고유값은 분산의 크기, 고유벡터는 분산의 방향 데이터 셋 준비 Normalize by each features 특성 데이터의 공분산 행렬 구하기 3에서 구한 공분산 행렬의 고유값, 고유 벡터 구하기 고유값을 큰 순서대로 내림차순 정렬 d 차원으로 줄이고 싶은 겨우, 크기 순서대로 d 개의 고유값 선정 6에서 선정한 고유값에 대응하는 고유벡터로 새로운 행렬 생성 1에서 준비한 데이터 7에서 만든 새로운 공간으로 투영PCAfrom sklearn.decomposition import PCApca = PCA(n_components = 50)pca.fit(fruits_2d)print(pca.components_.shape)# (50, 10000)fruits_pca = pca.transform(fruits_2d)print(fruits_pca.shape)# (300, 50)설명된 분산(Explained Variance) 주성분이 원본 데이터의 분산을 얼마나 잘 나타내는 지 기록한 값 아무리 고차원의 데이터여도 적은 차원으로 데이터가 표현이 가능하다커널 PCA 기존 PCA를 일반화한 방법으로 비선형적으로 수행하는 방법 Input space 를 커널을 통해 고차원으로 mapping해서 linear하게 seperable 하게 만들어준다 Kernel : 저차원의 data를 고차원으로 mapping 하는 것KernelPCAfrom sklearn.preprocessing import StandardScalerstd_scale = StandardScaler()std_scale.fit(X_tn)X_tn_std = std_scale.transform(X_tn)X_te_std = std_scale.transform(X_te)from sklearn.decomposition import KernelPCAk_pca = KernelPCA(n_componenets=2, kernel = &#39;poly&#39;)k_pca.fit(X_tn_std)X_tn_kpca = k_pca.transform(X_tn_std)X_te_kpca = k_pca.transform(X_te_std)PCA + LogisticRegressionfrom sklearn.linear_model import LogisticRegressionlr = LogisticRegression(I)target = np.array([0] * 100 + [1] * 100 + [2] * 100)pca = PCA(n_components=0.5)pca.fit(fruits_2d)print(pca.n_components_)# 2fruits_pca = pca.transform(fruits_2d)scores = cross_validate(lr, fruits_pca, target)from skelarn.cluster import KMeanskm = KMeans(n_clusters = 3, random_state = 42)km.fit(fruits_pca)print(np.unique(km.labels_, return_counts = True))" }, { "title": "Lesson 13 - Generative Models", "url": "/posts/Lesson14-Reinforce-Learning/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-02-13 22:08:02 +0900", "snippet": "Reinforcement LearningWhat is Reinforcement Learning?Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward.Agent: Agent does action in an environemnt. The agent’s purpose is to get as much reward with an action.Enviornment:The environment gives a state to the agent.Process of Reinforcement Learning Agent receives a State from the Environment Agent that has a state does an action Agent gets a reward from the action Then the agent gets a new agentWith Reinforcement Learning we can solve vairous problems Cart-Pole Problem Robot Locomotion Atari Games GoMarkov Decision ProcessesMarkov Decision Processes는 강화 학습 방법을 수식화 하는 것을 말한다Markov Property는 현재 상태로 전체 상태를 나타내는 것을 말한다Bellman EquationBellman Equation is a relation equation between current state value function and next state value functionIf State S is given, let’s say that Q* is known from Q-Value functionQ* is the maximum reward you can get from an action. Therefore, knowing this we can find the best path at the next state S’Intuitively, knowing Q* will allow us to get the best reward on the next state S’Value iteration algorithmWe can gradually optimize the value of Q* with Bellman Equation by constantly updating itQ-LearningLet’s find out about how to approximate Q(s,a) with Neural Network.Loss function calculates the difference between Q(s,a) and Objective function ($\\displaystyle \\boldsymbol{y_i}$)($\\displaystyle \\boldsymbol{y_i}$) is the answer function satisfying Bellman equationDuring the Backward Pass process ($\\displaystyle \\boldsymbol{\\theta}$)Policy GradientsThere is also a problem with Q-learningThe problem is that the function is too complicated!The Q - value value must exist for all states.However, in the case of the example we saw earlier, the number of states were relatively small in four directions.For example, if you solve the problem of robots picking up objects with reinforcement learning,The state dimension is very high.So a new method has been proposed which is learning the policy itself rather than learning the Q-value values according to the state that is suggested.The method explained above is called Policy Gradients." }, { "title": "Lesson 13 - Generative Models", "url": "/posts/Lesson13-Generative-Models/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-02-07 23:11:02 +0900", "snippet": "Generative ModelsLesson13Supervised Learning- Data (x, y): x is data, y is label- Goal: Learn a function to map x → y- eg) classification, regression, object detection, semantic segmentation, image captioning ### Unsupervised Learning- Data x: just data, no label- Goal: Learn some underlying hidden structure of the data- eg) Clustering, dimensionality reduction, feature learning, density estimation ### Generatvie Models- it creates realistic samples- most popular model: PixelRNN/CNN, Variational Auto-encoder, GAN ### Pixel RNN/CNN- fully visible belief network- explicit density model- PixelRNN is sequentially generated so it is very slow- PixelCNN is faster than PixelRNN but still slow- Pros: - can explicitly compute likelihood - explicit likelihood of training data gives good evaluation metric - good samples- Con: - Sequential generation → slow ### Variational Autoencoders (VAE)- Input data → Encoder → Features → Decoder → Reconstructed Data → L2 Loss function- Encoder can be used to initialize a supervised model- Pros: - Principled approach to generative models - Allows inference of q(z|x), can be useful feature representation for other tasks- Cons: - Maximizes lower bound of likelihood: okay, but not as good evaluation as PixelRNN/PixelCNN - Samples blurrier and lower quality compared to state-of-the-art ### GANs- **Generator network**: try to fool the discriminator by generating real-looking images- **Discriminator network**: try to distinguish between real and fake images- **DCGAN**: CNN model and GAN model is combined" }, { "title": "Lesson 12 - Visualizing and Understanding", "url": "/posts/Lesson12-Visualizing-and-Understanding/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-02-06 20:40:06 +0900", "snippet": "Visualizing and UnderstandingLecture 12 Viusalize layers visualizing the first Convolution Layer visualizing the last Fully Connected Layer with t-SNE it converts the last layer output into 2 dimension Occlusion Experiments cover up the input image to see which part of the image was critical for classifying Draw heatmap of probability at each mask location Saliency Maps How to tell which pixels matter for classification Can be used for segmentation Intermediate features via (guided) backprop compute gradient of neuron value with respect to image pixels only backprop positive gradients Gradient ascent Deep Dream Amplify existing features Neural Style Transfer Style transfer requires many forward " }, { "title": "Lesson 11 - Detection and Segmentation", "url": "/posts/Lesson11-Detection-and-Segmentation/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-02-05 22:33:11 +0900", "snippet": "Detection and SegmentationLesson 11 Sementic Segmentation every pixel in the image is categorized downsides: don’t differentiate instances Sliding Window very inefficient, not really used Fully Convolutional stack multiple convolutional layers to preserve all pixels design network as a bunch of convolutional layers with downsampling and upsampling inside the network Transpose Convolution learnable upsampling input gives weight for filter stride gives ratio between movement in output and input the overlapping region is added Classification + Localization two fully connected layer for classification and box coordinates two loss for classification and box coordinates Softmax loss for classification, L2 loss for bounding box coordinates Object Detection using Sliding Window is a bad idea Region Proposals (RCNN) look for blobby regions and give candidates of the bounding boxes the regions will have different sizes so must be warped to a fixed size for ConvNet Problems computationally expensive training slow + inference is slow Ad hoc traning objectives Fast R-CNN first run the input to ConvNet rather than running each region proposals to the ConvNet ROI is extracted from the output from ConvNet (feature map of image) Problem The computing the region proposal bottlenecks the model Computing 2000 region proposal takes about 2seconds Test time takes less than 1 second Faster R-CNN Region Proposal Network is used to predict proposals from features YOLO / SSD Instance Segmentation Mask R-CNN CNN → ROI → CONV → CONV → a segmentation mask for each classes → Classification scores, Box Coordinates " }, { "title": "Lesson 10 - Recurrent Neural Networks", "url": "/posts/Lesson10-Recurrent-Neural-Networks/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-02-04 21:48:23 +0900", "snippet": "Recurrent Neural NetworksLecture 10 Recurrent Neural Network Has a hidden state that feeds back every time step hidden state updates when an input comes in Back propagation might take forever if data is big → Truncated back propagation can be used to solve this problem LSTM (Long Short Term Memory) two hidden state (hidden state, cell state) Cell State it has 4 gates (i, f, o, g) i : input gate, whether to write to cell f : forget gate, wheter to erase cell g: how much to write to cell o : how much to reveal cell " }, { "title": "ResNet Paper Review", "url": "/posts/ResNet-paper-review/", "categories": "Paper Review", "tags": "computer_vision", "date": "2022-02-04 13:12:04 +0900", "snippet": "ResNet : Deep Residual Learning for Imgae RecognitionBig PictureTheoretically the deeper the network the better the performance.However, before ResNet was released the performance got worse as the network got deeper.ResNet solved this problem.Before ResNet, VGG Network had the best performance. It has a small 3 x 3 convolutional filter, which makes a deep layer with a lot of channels.SummaryResNet uses residual block to reduce the difficulty of optimization.$\\displaystyle \\boldsymbol{F = W_2\\sigma(W_1x)}$↓$\\displaystyle \\boldsymbol{y = F(x, {W_i}) + W_sx}$Paper ReviewAbstract reformulated the layers as learning residual functions with reference to the layer inputs instead of learning unreferenced functions residual networks are easier to optimize and can gain accuracy from considerably increased depthIntroduction Very deep models had a problem of vanishing/exploding gradients Formally $\\displaystyle \\boldsymbol{H(x)}$ was used for training Instead of using $\\displaystyle \\boldsymbol{H(x)}$, stacking nonlinear layers called $\\displaystyle \\boldsymbol{F(x): H(x) - x}$ is used $\\displaystyle\\boldsymbol{F(x)}$ is later recasted into $\\displaystyle\\boldsymbol{F(x)+x}$ ResNet had better accuracy as the layers got deeperResidual Learning Identity mapping = Shorcut connection Instead of training with identity mapping, adding it is much simpler uses much less parameters makes optimization easier" }, { "title": "Lesson 9 - CNN Architectures", "url": "/posts/Lesson9-CNN-Architectures/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-02-02 13:21:04 +0900", "snippet": "CNN ArchitecturesLecture 9 LeNet-5 first Conv-net AlexNet first large scale CNN conv → pool → normalization → fc VGGNet small filters, deeper networks stacking three 3 x 3 conv layers which will have the same effective receptive field as one 7 x 7 conv layer GoogLeNet deeper layer: 22 layers “Inception module” Apply parallel filter operations on the input from previous layer Concatenate all filter outputs together depth-wise Very expensive compute Pooling layer preserves feature depth → depth increases uncontrollably Solution for very large depth from inception module “bottleneck” layer 1 x 1 conv layer for reducing depth dimension Auxiliary Classification outputs allows to inject additional gradient at lower layers No FC layers ResNet Hypothesis: deeper models are harder to optimize → Solution: Use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping Very deep networks using residual connections Network in Network (NiN)" }, { "title": "Lesson 7 - Training Neural Networks Part 2", "url": "/posts/Lesson7-Training-Neural-Networks2/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-01-23 19:53:32 +0900", "snippet": "Training Neural Networks Part 2OptimizationProblems with SGD if loss changes quickly in one direction and slowly in anotherVery slow progress along shallow dimension, jitter along steep direction if the loss function has a local minima or saddle point Zero gradient, gradient descent gets stuck SGD + Momentum build up “velocity” as a running mean of gradients Rho gives “friction”, typically rho - 0.9 or 0.99$\\displaystyle \\boldsymbol{v_{t + 1} = \\rho v_t + \\nabla f(x_t)}$$\\displaystyle \\boldsymbol{x_{t+1} = x_t - \\alpha v_{t+1}}$Nesterov Momentum$\\displaystyle \\boldsymbol{v_{t + 1} = \\rho v_t - \\alpha \\nabla f(x_t + \\rho v_t)}$$\\displaystyle \\boldsymbol{x_{t+1} = x_t + v_{t+1}}$AdaGrad added elemeny-wise scaling of the gradient based on the historical sum of squares in each dimensionRMSProp add decay rate to AdaGradAdam Momentum, Bias Correction, AdaGrad/ RMSProp is includeRegularization Common use: L2 Regularization L1 Regularization Elastic net (L1 + L2) Dropout in each forward pass, randomly set some neurons to zero Data Augmentation Horizontal Flips Random crops and scales Color Jitter Transfer Learning" }, { "title": "Lesson 6 - Training Neural Networks Part 1", "url": "/posts/Lesson6-Training-Neural-Networks1/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-01-22 13:12:04 +0900", "snippet": "Training Neural Networks Part 1Overview One time setup activation functions, preprocessing, weight initialization, regularization, gradient checking Training dynamics babysitting the learning process, parameter updates, hyperparameter optimization Evaluation model ensembles Activation FunctionsSigmoid$\\displaystyle \\boldsymbol{\\sigma(x)=1/(1+e^{-x})}$ squashes numbers to range [0, 1]3 problems: Saturated neurons kill the gradient Sigmoid outputs are not zero-centered exp() is a bit compute expensivetanh(x) squashes numbers to range [-1, 1] zero centered however still kills gradients when saturatedReLU does not saturate in + regions very computationally efficient converges faster than sigmoid and tanhProblems not zero-centered output it might die and never activateLeaky ReLU does not saturae computationally efficient will not “die”Exponential Linear Units (ELU) all benefits of ReLU closer to zero mean outputs negative saturation regime compared with Leaky ReLU adds some robustness to noiseProblems Computation requires exp() which is expensiveData Preprocessing make the data zero-centered normalize the dataWeight Initialization First idea: Small random numbers works okay for small networks but problems with deeper networks the gradient will get smaller and smaller Xavier initialization tries to match the weight by input size’s variance this is used a lot Batch Normalization compute the empirical mean and variance independently for each dimenstion Normalize usually inserted after Fully Connected or Concolutional layers and before nonlinearity$\\displaystyle \\boldsymbol{\\hat{x}^k = {x^k - E[x^k]\\over \\sqrt{Var[x^k]}}}$ improves gradient flow allows higher learning rates reduce strong dependence on initialization act as a form of regularizationBabysitting the Learning Process Preprocess the data Choose the architecture double check that the loss is reasonable train on a small data and try to overfit if loss is not going down: learning rate is too low if loss is exploding: learning rate too high Hyper Parameter Optimization coarse → fine First Stage: only a few epochs to get rough idea of what params work Second Stage: longer running time, finer search change parameters in log space when appropriate" }, { "title": "Lesson 5 - Convolutional Neural Networks", "url": "/posts/Lesson5-Convolutional-Neural-Networks/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-01-21 14:57:26 +0900", "snippet": "Convolutional Neural NetworksDifferent Types of LayersFully Connected Layer Stretch image to 1 layerConvolution Layer preserves spatial structure filter is used and it always extend the full depth of the input volume the result is layers of activation map ( CONV → RELU → CONV → RELU → POOL ) X n times and at the end use fully connected layer Zero padding is used for keeping the Image sizePooling Layer makes the representations smaller and more manageable downsampling" }, { "title": "Lesson 4 - Backpropagation and Neural Networks", "url": "/posts/Lesson4-Neural-Networks/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-01-20 18:12:04 +0900", "snippet": "Backpropagation and Neural Networks Numerical gradient is slow and approximate but easy to write Analytic gradient is fast and exact but easy to make mistakes Chain rule is used during backpropagation Backpropagation : Upstream gradient * local gradientBackpropagation exampleeg) the gradient of the sigmoid function is $\\boldsymbol{(1 - a(x)) \\times a(x)}$Patterns in backward flowadd gate: gradient distributormax gate: gradient routermul gate: gradient switcher  backpropagation = recursive application of the chain rule along a computational graph to compute the gradients of all inputs / parameters / intermediates forward : compute result of an operation and save any intermediates needed for gradient computation in memory backward : apply the chain rule to compute the gradient of the loss funciton with respect to the inputsNeural Networks (without the brain stuff)Activation Functions Architectures the layers are fully connected" }, { "title": "Lesson 3 - Loss Fucntion and Optimization", "url": "/posts/Lesson3-LossFunction-Optimization/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-01-19 19:32:23 +0900", "snippet": "Lesson 3 - Loss Function and Optimization Define a loss function that quantifies our unhappiness with the scores across the training data Come up with a way of efficiently finding the parameters that minimize the loss function which is optimizationLoss Function it tells us how good our current classifier is loss over the dataset is a sum of loss over examples general loss function is shown below$\\displaystyle\\boldsymbol {L = {1 \\over N} \\sum L_i (f(x_i, W), y_i)}0$ Multiclass SVM Loss$\\displaystyle\\boldsymbol {L_i = \\sum_{j\\neq y} max(0, s_j - s_{y_i} + 1)}$ Regularization$\\displaystyle\\boldsymbol{\\lambda R(W)}$$\\boldsymbol \\lambda$ = regularization strength (hyperparameter)In common use:5 L2 regularization : $\\displaystyle \\boldsymbol{R(W) = \\sum_k \\sum_l W_{k,l}^2} $ L1 regularization : $\\displaystyle \\boldsymbol{R(W) = \\sum_k \\sum_l \\vert W_{k,l} \\vert} $ Elastic net (L1 + L2) : $\\displaystyle \\boldsymbol{ R(W) = \\sum_k \\sum_l \\beta W_{k,l}^2 + \\vert W_{k,l} \\vert} $ Batch normalization, stochastic depthL2 is often used for weight decayL1 is often used to pick out features Softmax Classifier→ Multinominal Logistic Gregression scores : unnormalized log probabilities of the classes Softmax function $\\displaystyle \\boldsymbol{e^sk \\over \\sum_j{e^sj}}$ trys to minimized the negative log likelihood of the correct classLoss function:$\\displaystyle \\boldsymbol{L_i = -\\log P(Y = y_i \\vert X = x_i)}$     $\\displaystyle \\boldsymbol{= - \\log ({e^sk \\over \\sum_j{e^sj}})} $OptimizationDifferent strategies to optimize Random search: very bad idea Follow the slope: $\\displaystyle \\boldsymbol{{df(x)\\over dx} = \\lim_{h\\to0}{f(x+h) - f(x)\\over h}}$ in 1-dimnsion the derivative of a function in multiple dimensions the gradient is the vector of along each dimension the slope in any direction is the dot product of the direction with the gradient the direction of steepest descent is the negative gradient however numerical gradient is not usefull instead using analytic gradient is recommended Stochastic Gradient Descent (SGD) traditionally adding all the losses can be a very expensive calculation when N is large! instead of traditionally adding all the losses from the whole dataset, using a minibatch to approximate the sum of losses is used " }, { "title": "Lesson 2 - Image Classification", "url": "/posts/Lesson2-Image-Classification/", "categories": "CS231n", "tags": "computer_vision", "date": "2022-01-18 17:35:00 +0900", "snippet": "Lesson 2 - Image Classification PipelineData-Driven Approach Collect a dataset of images and labels Use Machine Learning to train a classifier Evaluate the classifier on new images Nearest Neighbor Train function memorize all data and labels Predict function predicts the label of the most similar training image With N examples, how fast are training and prediction? Train is O(1) Predict is O(n) → This is bad because we want fast predictions  Distance MetricL1 distancepixel-wise absolute value differences$\\displaystyled_1(I_1, I_2) = \\sum_{p}\\vert I_1^p - I_2^p\\vert$L2 (Euclidean) distance$\\displaystyled_2(I_1, I_2) = \\sqrt{\\sum_{p}(I_1^p - I_2^p)^2}$Setting Hyperparameters Choose approperiate hyperparameters Split data into train, val, and test Cross-Validation: Split data into foldsLinear Classification$f(x, W) = Wx + b$$W$ : parameters or weights$x$ : input image$b$ : bias" } ]
