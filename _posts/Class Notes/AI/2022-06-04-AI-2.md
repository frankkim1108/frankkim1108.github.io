---
title: Introduction to NN Chapter 2
date: 2022-06-04 20:07:18 +0900
categories: [AI]
tags: [study]    # TAG names should always be lowercase
use_math: true
---

XOR problem can’t be solved with just a single linear classifier so multiple nodes are needed

## **Brains in Nature**

- Brains in Nature can do sophisticated things and they are resilient
- Neurons are all connected and send signals
- 뉴런이 더 자주 사용하면 strong 해진다

Neurons are activated when the signal is over the threshold

- Digital → Analog으로 변환하기 위해서 Sigmoid 함수 사용
- $y = 1/(1 + e^{-x})$
- Weight are adjustable parameters
- 초기 weight는 random 값이다
- Data를 학습시키는 것은 weight 조절하는 것이다

Gradient descent is a practical way of finding the minimum of difficult functions

You can avoid overshooting by talking smaller steps which is smaller learning rate

Data를 가지고 학습한다는 뜻은 weight를 tuning한다는 뜻이다

데이터의 편협성: 학습은 주어진 데이터로만 하기 때문에 잘못된 방향으로 학습이 될 수 있다